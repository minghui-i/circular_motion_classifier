{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minghui-i/circular_motion_classifier/blob/main/circular_motion_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DPNX-hXKMiy",
        "outputId": "16e95cf8-9830-4978-dd0f-5e2f9e00b316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUdJXuMkJRUR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQsvD2C5Jwwz"
      },
      "outputs": [],
      "source": [
        "class FramesDataset(Dataset):\n",
        "  def __init__(self, data_pd):\n",
        "    self.data_pd = data_pd\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_pd)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data_pd.iloc[index]['Tensor'], self.data_pd.iloc[index]['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiSCnpTdJ9Xg"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/Object Detection/TrainTensors')\n",
        "data_df = torch.load('AugementTrain.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI_zam26T612"
      },
      "outputs": [],
      "source": [
        "for x in range(len(data_df['Label'])):\n",
        "  if data_df['Label'].iloc[x] == 'False':\n",
        "    data_df['Label'].iloc[x] = 0\n",
        "  else:\n",
        "    data_df['Label'].iloc[x] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxqZ2urSKCbR"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/Object Detection/TestTensors')\n",
        "data_df_test = torch.load(\"AugementTester.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTwcllj3_aym"
      },
      "outputs": [],
      "source": [
        "for x in range(len(data_df_test['Label'])):\n",
        "  if data_df_test['Label'].iloc[x] == '0' or 0:\n",
        "    data_df_test['Label'].iloc[x] = 0\n",
        "  elif data_df_test['Label'].iloc[x] == '1' or 1:\n",
        "    data_df_test['Label'].iloc[x] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48SutptLLTlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7bb8c5d-638d-45f3-fdb6-46d29fa84bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_dataset = FramesDataset(data_df)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ciV0J4sLZgQ"
      },
      "outputs": [],
      "source": [
        "test_dataset = FramesDataset(data_df_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od5YMazTK-2C"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 4, 5, 2)\n",
        "        self.conv2 = nn.Conv2d(4, 16, 5, 2)\n",
        "        self.fc1 = nn.Linear(576, 550)\n",
        "        self.fc2 = nn.Linear(550, 540)\n",
        "        self.fc3 = nn.Linear(540, 470)\n",
        "        self.fc4 = nn.Linear(470, 300)\n",
        "        self.fc5 = nn.Linear(300, 220)\n",
        "        self.fc6 = nn.Linear(220, 130)\n",
        "        self.fc7 = nn.Linear(130, 70)\n",
        "        self.fc8 = nn.Linear(70, 40)\n",
        "        self.fc9 = nn.Linear(40, 1)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 3, 3)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 3, 3)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.fc5(x)\n",
        "        x = self.fc6(x)\n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "        x = self.fc9(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME5JIeW9LL8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "753483a4-0918-4b7a-a870-cdc939b26d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = CNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXgZqT_eLned",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94bc7055-8629-41ee-d6dd-93a22fd0a6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 1,119,181 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "epochs = 2\n",
        "learning_rate = .0001\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {param_count:,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWu6thmSMSDN"
      },
      "outputs": [],
      "source": [
        "model = torch.compile(model, mode=\"reduce-overhead\")\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiL5vEM0MTz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02cb359-5465-4968-b9b4-b667de316853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "for batch_idx, (data, targets) in enumerate(train_dataloader):\n",
        "    outputs = model(data.to(device)).squeeze(1)\n",
        "    loss = criterion(outputs, targets.to(device).float())\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE9x60fAhBy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940a0bbb-619b-460d-ba5f-db5a390baac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01/02 | Batch: 00001/01887 | Loss: 0.6933 | Avg Loss: 0.6933 | Prediction: 0.031852830201387405 | Label: 1 | Time: 10.12 | Avg Time: 10.12 | Time Left: 1.909e+04\n",
            "Epoch: 01/02 | Batch: 00002/01887 | Loss: 0.6947 | Avg Loss: 0.694 | Prediction: 0.024335898458957672 | Label: 0 | Time: 0.5774 | Avg Time: 5.35 | Time Left: 1.008e+04\n",
            "Epoch: 01/02 | Batch: 00003/01887 | Loss: 0.6943 | Avg Loss: 0.6941 | Prediction: 0.018031645566225052 | Label: 0 | Time: 0.007185 | Avg Time: 3.569 | Time Left: 6.724e+03\n",
            "Epoch: 01/02 | Batch: 00004/01887 | Loss: 0.6918 | Avg Loss: 0.6935 | Prediction: 0.011043533682823181 | Label: 1 | Time: 0.004329 | Avg Time: 2.678 | Time Left: 5.042e+03\n",
            "Epoch: 01/02 | Batch: 00005/01887 | Loss: 0.6925 | Avg Loss: 0.6933 | Prediction: 0.011150605976581573 | Label: 0 | Time: 0.00422 | Avg Time: 2.143 | Time Left: 4.033e+03\n",
            "Epoch: 01/02 | Batch: 00006/01887 | Loss: 0.694 | Avg Loss: 0.6934 | Prediction: 0.012746404856443405 | Label: 0 | Time: 0.004565 | Avg Time: 1.787 | Time Left: 3.361e+03\n",
            "Epoch: 01/02 | Batch: 00007/01887 | Loss: 0.6924 | Avg Loss: 0.6933 | Prediction: 0.012571148574352264 | Label: 1 | Time: 0.009066 | Avg Time: 1.533 | Time Left: 2.881e+03\n",
            "Epoch: 01/02 | Batch: 00008/01887 | Loss: 0.694 | Avg Loss: 0.6934 | Prediction: 0.013565946370363235 | Label: 0 | Time: 0.01324 | Avg Time: 1.343 | Time Left: 2.523e+03\n",
            "Epoch: 01/02 | Batch: 00009/01887 | Loss: 0.6948 | Avg Loss: 0.6935 | Prediction: 0.013215754181146622 | Label: 0 | Time: 0.005782 | Avg Time: 1.194 | Time Left: 2.243e+03\n",
            "Epoch: 01/02 | Batch: 00010/01887 | Loss: 0.6932 | Avg Loss: 0.6935 | Prediction: 0.01101379469037056 | Label: 1 | Time: 0.01306 | Avg Time: 1.076 | Time Left: 2.02e+03\n",
            "Epoch: 01/02 | Batch: 00011/01887 | Loss: 0.6909 | Avg Loss: 0.6933 | Prediction: 0.00890987366437912 | Label: 0 | Time: 0.005002 | Avg Time: 0.9787 | Time Left: 1.836e+03\n",
            "Epoch: 01/02 | Batch: 00012/01887 | Loss: 0.6919 | Avg Loss: 0.6931 | Prediction: 0.010330624878406525 | Label: 0 | Time: 0.009615 | Avg Time: 0.898 | Time Left: 1.684e+03\n",
            "Epoch: 01/02 | Batch: 00013/01887 | Loss: 0.6908 | Avg Loss: 0.693 | Prediction: 0.012681908905506134 | Label: 1 | Time: 0.009942 | Avg Time: 0.8296 | Time Left: 1.555e+03\n",
            "Epoch: 01/02 | Batch: 00014/01887 | Loss: 0.6932 | Avg Loss: 0.693 | Prediction: 0.016069874167442322 | Label: 0 | Time: 0.008707 | Avg Time: 0.771 | Time Left: 1.444e+03\n",
            "Epoch: 01/02 | Batch: 00015/01887 | Loss: 0.6932 | Avg Loss: 0.693 | Prediction: 0.019131723791360855 | Label: 0 | Time: 0.01279 | Avg Time: 0.7205 | Time Left: 1.349e+03\n",
            "Epoch: 01/02 | Batch: 00016/01887 | Loss: 0.6932 | Avg Loss: 0.693 | Prediction: 0.02186831831932068 | Label: 0 | Time: 0.004453 | Avg Time: 0.6757 | Time Left: 1.264e+03\n",
            "Epoch: 01/02 | Batch: 00017/01887 | Loss: 0.6887 | Avg Loss: 0.6927 | Prediction: 0.024152323603630066 | Label: 0 | Time: 0.004183 | Avg Time: 0.6362 | Time Left: 1.19e+03\n",
            "Epoch: 01/02 | Batch: 00018/01887 | Loss: 0.6915 | Avg Loss: 0.6927 | Prediction: 0.027537699788808823 | Label: 0 | Time: 0.008523 | Avg Time: 0.6013 | Time Left: 1.124e+03\n",
            "Epoch: 01/02 | Batch: 00019/01887 | Loss: 0.6855 | Avg Loss: 0.6923 | Prediction: 0.031033270061016083 | Label: 1 | Time: 0.009685 | Avg Time: 0.5702 | Time Left: 1.065e+03\n",
            "Epoch: 01/02 | Batch: 00020/01887 | Loss: 0.6889 | Avg Loss: 0.6921 | Prediction: 0.03546074777841568 | Label: 1 | Time: 0.005128 | Avg Time: 0.5419 | Time Left: 1.012e+03\n",
            "Epoch: 01/02 | Batch: 00021/01887 | Loss: 0.6858 | Avg Loss: 0.6918 | Prediction: 0.04013710841536522 | Label: 0 | Time: 0.004462 | Avg Time: 0.5164 | Time Left: 963.5\n",
            "Epoch: 01/02 | Batch: 00022/01887 | Loss: 0.6792 | Avg Loss: 0.6913 | Prediction: 0.04546825587749481 | Label: 1 | Time: 0.009411 | Avg Time: 0.4933 | Time Left: 920.0\n",
            "Epoch: 01/02 | Batch: 00023/01887 | Loss: 0.6935 | Avg Loss: 0.6913 | Prediction: 0.05148501694202423 | Label: 1 | Time: 0.004637 | Avg Time: 0.4721 | Time Left: 879.9\n",
            "Epoch: 01/02 | Batch: 00024/01887 | Loss: 0.69 | Avg Loss: 0.6913 | Prediction: 0.05686795338988304 | Label: 0 | Time: 0.008167 | Avg Time: 0.4527 | Time Left: 843.4\n",
            "Epoch: 01/02 | Batch: 00025/01887 | Loss: 0.6858 | Avg Loss: 0.6911 | Prediction: 0.06222199648618698 | Label: 0 | Time: 0.008265 | Avg Time: 0.435 | Time Left: 809.9\n",
            "Epoch: 01/02 | Batch: 00026/01887 | Loss: 0.7022 | Avg Loss: 0.6915 | Prediction: 0.06789549440145493 | Label: 1 | Time: 0.01075 | Avg Time: 0.4186 | Time Left: 779.1\n",
            "Epoch: 01/02 | Batch: 00027/01887 | Loss: 0.6848 | Avg Loss: 0.6913 | Prediction: 0.07175399363040924 | Label: 0 | Time: 0.007715 | Avg Time: 0.4034 | Time Left: 750.4\n",
            "Epoch: 01/02 | Batch: 00028/01887 | Loss: 0.6748 | Avg Loss: 0.6907 | Prediction: 0.07607554644346237 | Label: 0 | Time: 0.00582 | Avg Time: 0.3892 | Time Left: 723.6\n",
            "Epoch: 01/02 | Batch: 00029/01887 | Loss: 0.6889 | Avg Loss: 0.6906 | Prediction: 0.08144637197256088 | Label: 1 | Time: 0.006819 | Avg Time: 0.376 | Time Left: 698.7\n",
            "Epoch: 01/02 | Batch: 00030/01887 | Loss: 0.7049 | Avg Loss: 0.6911 | Prediction: 0.08678027987480164 | Label: 0 | Time: 0.01051 | Avg Time: 0.3638 | Time Left: 675.7\n",
            "Epoch: 01/02 | Batch: 00031/01887 | Loss: 0.6829 | Avg Loss: 0.6908 | Prediction: 0.09018415212631226 | Label: 0 | Time: 0.003849 | Avg Time: 0.3522 | Time Left: 653.8\n",
            "Epoch: 01/02 | Batch: 00032/01887 | Loss: 0.6766 | Avg Loss: 0.6904 | Prediction: 0.09418834745883942 | Label: 0 | Time: 0.004338 | Avg Time: 0.3414 | Time Left: 633.2\n",
            "Epoch: 01/02 | Batch: 00033/01887 | Loss: 0.6819 | Avg Loss: 0.6901 | Prediction: 0.09929470717906952 | Label: 0 | Time: 0.0153 | Avg Time: 0.3315 | Time Left: 614.6\n",
            "Epoch: 01/02 | Batch: 00034/01887 | Loss: 0.6945 | Avg Loss: 0.6902 | Prediction: 0.1049489676952362 | Label: 0 | Time: 0.01135 | Avg Time: 0.3221 | Time Left: 596.8\n",
            "Epoch: 01/02 | Batch: 00035/01887 | Loss: 0.674 | Avg Loss: 0.6898 | Prediction: 0.11017748713493347 | Label: 1 | Time: 0.004022 | Avg Time: 0.313 | Time Left: 579.6\n",
            "Epoch: 01/02 | Batch: 00036/01887 | Loss: 0.673 | Avg Loss: 0.6893 | Prediction: 0.1163628101348877 | Label: 0 | Time: 0.007746 | Avg Time: 0.3045 | Time Left: 563.6\n",
            "Epoch: 01/02 | Batch: 00037/01887 | Loss: 0.6717 | Avg Loss: 0.6888 | Prediction: 0.12438651919364929 | Label: 0 | Time: 0.004419 | Avg Time: 0.2964 | Time Left: 548.3\n",
            "Epoch: 01/02 | Batch: 00038/01887 | Loss: 0.687 | Avg Loss: 0.6888 | Prediction: 0.13336347043514252 | Label: 0 | Time: 0.006981 | Avg Time: 0.2888 | Time Left: 533.9\n",
            "Epoch: 01/02 | Batch: 00039/01887 | Loss: 0.6778 | Avg Loss: 0.6885 | Prediction: 0.14309293031692505 | Label: 1 | Time: 0.009662 | Avg Time: 0.2816 | Time Left: 520.4\n",
            "Epoch: 01/02 | Batch: 00040/01887 | Loss: 0.696 | Avg Loss: 0.6887 | Prediction: 0.15372741222381592 | Label: 0 | Time: 0.008444 | Avg Time: 0.2748 | Time Left: 507.5\n",
            "Epoch: 01/02 | Batch: 00041/01887 | Loss: 0.6555 | Avg Loss: 0.6879 | Prediction: 0.16322720050811768 | Label: 0 | Time: 0.007679 | Avg Time: 0.2683 | Time Left: 495.2\n",
            "Epoch: 01/02 | Batch: 00042/01887 | Loss: 0.686 | Avg Loss: 0.6878 | Prediction: 0.17632868885993958 | Label: 1 | Time: 0.004437 | Avg Time: 0.262 | Time Left: 483.4\n",
            "Epoch: 01/02 | Batch: 00043/01887 | Loss: 0.6857 | Avg Loss: 0.6878 | Prediction: 0.18944528698921204 | Label: 0 | Time: 0.008673 | Avg Time: 0.2561 | Time Left: 472.3\n",
            "Epoch: 01/02 | Batch: 00044/01887 | Loss: 0.6982 | Avg Loss: 0.688 | Prediction: 0.20271781086921692 | Label: 0 | Time: 0.007544 | Avg Time: 0.2505 | Time Left: 461.6\n",
            "Epoch: 01/02 | Batch: 00045/01887 | Loss: 0.7388 | Avg Loss: 0.6892 | Prediction: 0.21374356746673584 | Label: 1 | Time: 0.004468 | Avg Time: 0.245 | Time Left: 451.3\n",
            "Epoch: 01/02 | Batch: 00046/01887 | Loss: 0.6721 | Avg Loss: 0.6888 | Prediction: 0.2128657102584839 | Label: 0 | Time: 0.005458 | Avg Time: 0.2398 | Time Left: 441.4\n",
            "Epoch: 01/02 | Batch: 00047/01887 | Loss: 0.6854 | Avg Loss: 0.6887 | Prediction: 0.21514543890953064 | Label: 1 | Time: 0.004903 | Avg Time: 0.2348 | Time Left: 432.0\n",
            "Epoch: 01/02 | Batch: 00048/01887 | Loss: 0.7124 | Avg Loss: 0.6892 | Prediction: 0.21696272492408752 | Label: 0 | Time: 0.01122 | Avg Time: 0.2301 | Time Left: 423.2\n",
            "Epoch: 01/02 | Batch: 00049/01887 | Loss: 0.6988 | Avg Loss: 0.6894 | Prediction: 0.21468514204025269 | Label: 0 | Time: 0.01165 | Avg Time: 0.2257 | Time Left: 414.8\n",
            "Epoch: 01/02 | Batch: 00050/01887 | Loss: 0.6986 | Avg Loss: 0.6896 | Prediction: 0.21199670433998108 | Label: 1 | Time: 0.005626 | Avg Time: 0.2213 | Time Left: 406.5\n",
            "Epoch: 01/02 | Batch: 00051/01887 | Loss: 0.6984 | Avg Loss: 0.6898 | Prediction: 0.20760667324066162 | Label: 1 | Time: 0.01126 | Avg Time: 0.2171 | Time Left: 398.7\n",
            "Epoch: 01/02 | Batch: 00052/01887 | Loss: 0.6602 | Avg Loss: 0.6892 | Prediction: 0.20167751610279083 | Label: 0 | Time: 0.009442 | Avg Time: 0.2132 | Time Left: 391.1\n",
            "Epoch: 01/02 | Batch: 00053/01887 | Loss: 0.6603 | Avg Loss: 0.6886 | Prediction: 0.20131266117095947 | Label: 0 | Time: 0.005138 | Avg Time: 0.2092 | Time Left: 383.7\n",
            "Epoch: 01/02 | Batch: 00054/01887 | Loss: 0.6345 | Avg Loss: 0.6876 | Prediction: 0.20397046208381653 | Label: 1 | Time: 0.007043 | Avg Time: 0.2055 | Time Left: 376.7\n",
            "Epoch: 01/02 | Batch: 00055/01887 | Loss: 0.6589 | Avg Loss: 0.6871 | Prediction: 0.21084654331207275 | Label: 1 | Time: 0.009975 | Avg Time: 0.2019 | Time Left: 369.9\n",
            "Epoch: 01/02 | Batch: 00056/01887 | Loss: 0.7269 | Avg Loss: 0.6878 | Prediction: 0.22224608063697815 | Label: 1 | Time: 0.006439 | Avg Time: 0.1984 | Time Left: 363.3\n",
            "Epoch: 01/02 | Batch: 00057/01887 | Loss: 0.7278 | Avg Loss: 0.6885 | Prediction: 0.22599878907203674 | Label: 0 | Time: 0.005089 | Avg Time: 0.195 | Time Left: 356.9\n",
            "Epoch: 01/02 | Batch: 00058/01887 | Loss: 0.6994 | Avg Loss: 0.6887 | Prediction: 0.2268437296152115 | Label: 1 | Time: 0.00898 | Avg Time: 0.1918 | Time Left: 350.9\n",
            "Epoch: 01/02 | Batch: 00059/01887 | Loss: 0.6992 | Avg Loss: 0.6889 | Prediction: 0.22396798431873322 | Label: 0 | Time: 0.01089 | Avg Time: 0.1888 | Time Left: 345.1\n",
            "Epoch: 01/02 | Batch: 00060/01887 | Loss: 0.6715 | Avg Loss: 0.6886 | Prediction: 0.22230462729930878 | Label: 0 | Time: 0.005217 | Avg Time: 0.1857 | Time Left: 339.3\n",
            "Epoch: 01/02 | Batch: 00061/01887 | Loss: 0.6852 | Avg Loss: 0.6886 | Prediction: 0.22038424015045166 | Label: 0 | Time: 0.004841 | Avg Time: 0.1827 | Time Left: 333.7\n",
            "Epoch: 01/02 | Batch: 00062/01887 | Loss: 0.6715 | Avg Loss: 0.6883 | Prediction: 0.22089365124702454 | Label: 1 | Time: 0.006874 | Avg Time: 0.1799 | Time Left: 328.3\n",
            "Epoch: 01/02 | Batch: 00063/01887 | Loss: 0.6714 | Avg Loss: 0.688 | Prediction: 0.2220301777124405 | Label: 1 | Time: 0.009957 | Avg Time: 0.1772 | Time Left: 323.2\n",
            "Epoch: 01/02 | Batch: 00064/01887 | Loss: 0.6992 | Avg Loss: 0.6882 | Prediction: 0.224874347448349 | Label: 1 | Time: 0.01621 | Avg Time: 0.1747 | Time Left: 318.5\n",
            "Epoch: 01/02 | Batch: 00065/01887 | Loss: 0.6288 | Avg Loss: 0.6873 | Prediction: 0.22606226801872253 | Label: 1 | Time: 0.008377 | Avg Time: 0.1721 | Time Left: 313.6\n",
            "Epoch: 01/02 | Batch: 00066/01887 | Loss: 0.6705 | Avg Loss: 0.687 | Prediction: 0.23311400413513184 | Label: 1 | Time: 0.01427 | Avg Time: 0.1697 | Time Left: 309.1\n",
            "Epoch: 01/02 | Batch: 00067/01887 | Loss: 0.685 | Avg Loss: 0.687 | Prediction: 0.2416035234928131 | Label: 1 | Time: 0.01152 | Avg Time: 0.1674 | Time Left: 304.6\n",
            "Epoch: 01/02 | Batch: 00068/01887 | Loss: 0.6383 | Avg Loss: 0.6863 | Prediction: 0.2492610663175583 | Label: 0 | Time: 0.008715 | Avg Time: 0.1651 | Time Left: 300.2\n",
            "Epoch: 01/02 | Batch: 00069/01887 | Loss: 0.685 | Avg Loss: 0.6863 | Prediction: 0.26305854320526123 | Label: 1 | Time: 0.005189 | Avg Time: 0.1627 | Time Left: 295.9\n",
            "Epoch: 01/02 | Batch: 00070/01887 | Loss: 0.7537 | Avg Loss: 0.6872 | Prediction: 0.2758593261241913 | Label: 1 | Time: 0.01631 | Avg Time: 0.1606 | Time Left: 291.9\n",
            "Epoch: 01/02 | Batch: 00071/01887 | Loss: 0.6676 | Avg Loss: 0.6869 | Prediction: 0.27577105164527893 | Label: 0 | Time: 0.005981 | Avg Time: 0.1585 | Time Left: 287.8\n",
            "Epoch: 01/02 | Batch: 00072/01887 | Loss: 0.7026 | Avg Loss: 0.6872 | Prediction: 0.2814944088459015 | Label: 1 | Time: 0.007753 | Avg Time: 0.1564 | Time Left: 283.8\n",
            "Epoch: 01/02 | Batch: 00073/01887 | Loss: 0.6498 | Avg Loss: 0.6866 | Prediction: 0.2823377847671509 | Label: 1 | Time: 0.009218 | Avg Time: 0.1544 | Time Left: 280.0\n",
            "Epoch: 01/02 | Batch: 00074/01887 | Loss: 0.7031 | Avg Loss: 0.6869 | Prediction: 0.2846809923648834 | Label: 0 | Time: 0.007151 | Avg Time: 0.1524 | Time Left: 276.2\n",
            "Epoch: 01/02 | Batch: 00075/01887 | Loss: 0.7391 | Avg Loss: 0.6876 | Prediction: 0.289937824010849 | Label: 1 | Time: 0.005519 | Avg Time: 0.1504 | Time Left: 272.5\n",
            "Epoch: 01/02 | Batch: 00076/01887 | Loss: 0.7202 | Avg Loss: 0.688 | Prediction: 0.28435105085372925 | Label: 1 | Time: 0.005567 | Avg Time: 0.1485 | Time Left: 268.9\n",
            "Epoch: 01/02 | Batch: 00077/01887 | Loss: 0.7193 | Avg Loss: 0.6884 | Prediction: 0.2748708426952362 | Label: 0 | Time: 0.009009 | Avg Time: 0.1467 | Time Left: 265.5\n",
            "Epoch: 01/02 | Batch: 00078/01887 | Loss: 0.6849 | Avg Loss: 0.6884 | Prediction: 0.2632882595062256 | Label: 0 | Time: 0.009329 | Avg Time: 0.1449 | Time Left: 262.2\n",
            "Epoch: 01/02 | Batch: 00079/01887 | Loss: 0.6691 | Avg Loss: 0.6881 | Prediction: 0.25062304735183716 | Label: 0 | Time: 0.006906 | Avg Time: 0.1432 | Time Left: 258.9\n",
            "Epoch: 01/02 | Batch: 00080/01887 | Loss: 0.6849 | Avg Loss: 0.6881 | Prediction: 0.24425345659255981 | Label: 0 | Time: 0.009521 | Avg Time: 0.1415 | Time Left: 255.7\n",
            "Epoch: 01/02 | Batch: 00081/01887 | Loss: 0.6849 | Avg Loss: 0.688 | Prediction: 0.2397090643644333 | Label: 0 | Time: 0.007893 | Avg Time: 0.1399 | Time Left: 252.6\n",
            "Epoch: 01/02 | Batch: 00082/01887 | Loss: 0.6849 | Avg Loss: 0.688 | Prediction: 0.23477166891098022 | Label: 0 | Time: 0.007978 | Avg Time: 0.1383 | Time Left: 249.5\n",
            "Epoch: 01/02 | Batch: 00083/01887 | Loss: 0.6849 | Avg Loss: 0.688 | Prediction: 0.23134192824363708 | Label: 1 | Time: 0.009938 | Avg Time: 0.1367 | Time Left: 246.6\n",
            "Epoch: 01/02 | Batch: 00084/01887 | Loss: 0.7134 | Avg Loss: 0.6883 | Prediction: 0.22774213552474976 | Label: 1 | Time: 0.008262 | Avg Time: 0.1352 | Time Left: 243.7\n",
            "Epoch: 01/02 | Batch: 00085/01887 | Loss: 0.6296 | Avg Loss: 0.6876 | Prediction: 0.22230646014213562 | Label: 1 | Time: 0.01011 | Avg Time: 0.1337 | Time Left: 240.9\n",
            "Epoch: 01/02 | Batch: 00086/01887 | Loss: 0.6849 | Avg Loss: 0.6875 | Prediction: 0.21962690353393555 | Label: 0 | Time: 0.005515 | Avg Time: 0.1322 | Time Left: 238.1\n",
            "Epoch: 01/02 | Batch: 00087/01887 | Loss: 0.6849 | Avg Loss: 0.6875 | Prediction: 0.21971464157104492 | Label: 0 | Time: 0.006356 | Avg Time: 0.1308 | Time Left: 235.4\n",
            "Epoch: 01/02 | Batch: 00088/01887 | Loss: 0.6433 | Avg Loss: 0.687 | Prediction: 0.2227630615234375 | Label: 1 | Time: 0.007828 | Avg Time: 0.1294 | Time Left: 232.7\n",
            "Epoch: 01/02 | Batch: 00089/01887 | Loss: 0.6707 | Avg Loss: 0.6868 | Prediction: 0.22653180360794067 | Label: 1 | Time: 0.009065 | Avg Time: 0.128 | Time Left: 230.2\n",
            "Epoch: 01/02 | Batch: 00090/01887 | Loss: 0.6991 | Avg Loss: 0.687 | Prediction: 0.23093681037425995 | Label: 0 | Time: 0.008399 | Avg Time: 0.1267 | Time Left: 227.7\n",
            "Epoch: 01/02 | Batch: 00091/01887 | Loss: 0.6704 | Avg Loss: 0.6868 | Prediction: 0.23488759994506836 | Label: 1 | Time: 0.009254 | Avg Time: 0.1254 | Time Left: 225.2\n",
            "Epoch: 01/02 | Batch: 00092/01887 | Loss: 0.6846 | Avg Loss: 0.6868 | Prediction: 0.23623210191726685 | Label: 0 | Time: 0.007953 | Avg Time: 0.1241 | Time Left: 222.8\n",
            "Epoch: 01/02 | Batch: 00093/01887 | Loss: 0.6696 | Avg Loss: 0.6866 | Prediction: 0.2439422905445099 | Label: 1 | Time: 0.004972 | Avg Time: 0.1228 | Time Left: 220.4\n",
            "Epoch: 01/02 | Batch: 00094/01887 | Loss: 0.6692 | Avg Loss: 0.6864 | Prediction: 0.2455522119998932 | Label: 0 | Time: 0.009966 | Avg Time: 0.1216 | Time Left: 218.1\n",
            "Epoch: 01/02 | Batch: 00095/01887 | Loss: 0.6845 | Avg Loss: 0.6864 | Prediction: 0.25678130984306335 | Label: 1 | Time: 0.007106 | Avg Time: 0.1204 | Time Left: 215.8\n",
            "Epoch: 01/02 | Batch: 00096/01887 | Loss: 0.6515 | Avg Loss: 0.686 | Prediction: 0.25907301902770996 | Label: 0 | Time: 0.0103 | Avg Time: 0.1193 | Time Left: 213.6\n",
            "Epoch: 01/02 | Batch: 00097/01887 | Loss: 0.7693 | Avg Loss: 0.6869 | Prediction: 0.26885148882865906 | Label: 0 | Time: 0.01179 | Avg Time: 0.1182 | Time Left: 211.5\n",
            "Epoch: 01/02 | Batch: 00098/01887 | Loss: 0.6334 | Avg Loss: 0.6863 | Prediction: 0.273384690284729 | Label: 1 | Time: 0.004227 | Avg Time: 0.117 | Time Left: 209.3\n",
            "Epoch: 01/02 | Batch: 00099/01887 | Loss: 0.7361 | Avg Loss: 0.6868 | Prediction: 0.2737948000431061 | Label: 0 | Time: 0.004267 | Avg Time: 0.1159 | Time Left: 207.2\n",
            "Epoch: 01/02 | Batch: 00100/01887 | Loss: 0.6672 | Avg Loss: 0.6866 | Prediction: 0.27680206298828125 | Label: 1 | Time: 0.007576 | Avg Time: 0.1148 | Time Left: 205.1\n",
            "Epoch: 01/02 | Batch: 00101/01887 | Loss: 0.7187 | Avg Loss: 0.6869 | Prediction: 0.2714918851852417 | Label: 0 | Time: 0.004659 | Avg Time: 0.1137 | Time Left: 203.1\n",
            "Epoch: 01/02 | Batch: 00102/01887 | Loss: 0.7019 | Avg Loss: 0.6871 | Prediction: 0.27471739053726196 | Label: 1 | Time: 0.004346 | Avg Time: 0.1126 | Time Left: 201.1\n",
            "Epoch: 01/02 | Batch: 00103/01887 | Loss: 0.7014 | Avg Loss: 0.6872 | Prediction: 0.2694115936756134 | Label: 0 | Time: 0.00452 | Avg Time: 0.1116 | Time Left: 199.1\n",
            "Epoch: 01/02 | Batch: 00104/01887 | Loss: 0.635 | Avg Loss: 0.6867 | Prediction: 0.264737993478775 | Label: 1 | Time: 0.004985 | Avg Time: 0.1106 | Time Left: 197.1\n",
            "Epoch: 01/02 | Batch: 00105/01887 | Loss: 0.6678 | Avg Loss: 0.6865 | Prediction: 0.2579662501811981 | Label: 0 | Time: 0.008042 | Avg Time: 0.1096 | Time Left: 195.3\n",
            "Epoch: 01/02 | Batch: 00106/01887 | Loss: 0.7005 | Avg Loss: 0.6867 | Prediction: 0.25852251052856445 | Label: 0 | Time: 0.01118 | Avg Time: 0.1087 | Time Left: 193.5\n",
            "Epoch: 01/02 | Batch: 00107/01887 | Loss: 0.7006 | Avg Loss: 0.6868 | Prediction: 0.2654203772544861 | Label: 0 | Time: 0.01298 | Avg Time: 0.1078 | Time Left: 191.8\n",
            "Epoch: 01/02 | Batch: 00108/01887 | Loss: 0.6679 | Avg Loss: 0.6866 | Prediction: 0.26472657918930054 | Label: 1 | Time: 0.005226 | Avg Time: 0.1068 | Time Left: 190.0\n",
            "Epoch: 01/02 | Batch: 00109/01887 | Loss: 0.6681 | Avg Loss: 0.6865 | Prediction: 0.2649003863334656 | Label: 1 | Time: 0.005087 | Avg Time: 0.1059 | Time Left: 188.3\n",
            "Epoch: 01/02 | Batch: 00110/01887 | Loss: 0.6014 | Avg Loss: 0.6857 | Prediction: 0.26650065183639526 | Label: 1 | Time: 0.005364 | Avg Time: 0.105 | Time Left: 186.5\n",
            "Epoch: 01/02 | Batch: 00111/01887 | Loss: 0.6847 | Avg Loss: 0.6857 | Prediction: 0.2769089341163635 | Label: 1 | Time: 0.004774 | Avg Time: 0.1041 | Time Left: 184.8\n",
            "Epoch: 01/02 | Batch: 00112/01887 | Loss: 0.6485 | Avg Loss: 0.6853 | Prediction: 0.2861340641975403 | Label: 1 | Time: 0.008728 | Avg Time: 0.1032 | Time Left: 183.2\n",
            "Epoch: 01/02 | Batch: 00113/01887 | Loss: 0.7024 | Avg Loss: 0.6855 | Prediction: 0.29940420389175415 | Label: 1 | Time: 0.004442 | Avg Time: 0.1023 | Time Left: 181.5\n",
            "Epoch: 01/02 | Batch: 00114/01887 | Loss: 0.6451 | Avg Loss: 0.6851 | Prediction: 0.3094549775123596 | Label: 1 | Time: 0.01043 | Avg Time: 0.1015 | Time Left: 180.0\n",
            "Epoch: 01/02 | Batch: 00115/01887 | Loss: 0.6639 | Avg Loss: 0.685 | Prediction: 0.3239494264125824 | Label: 1 | Time: 0.008849 | Avg Time: 0.1007 | Time Left: 178.5\n",
            "Epoch: 01/02 | Batch: 00116/01887 | Loss: 0.7046 | Avg Loss: 0.6851 | Prediction: 0.325518935918808 | Label: 0 | Time: 0.008715 | Avg Time: 0.09993 | Time Left: 177.0\n",
            "Epoch: 01/02 | Batch: 00117/01887 | Loss: 0.6831 | Avg Loss: 0.6851 | Prediction: 0.3516252040863037 | Label: 1 | Time: 0.004999 | Avg Time: 0.09912 | Time Left: 175.4\n",
            "Epoch: 01/02 | Batch: 00118/01887 | Loss: 0.6614 | Avg Loss: 0.6849 | Prediction: 0.36220574378967285 | Label: 1 | Time: 0.006603 | Avg Time: 0.09834 | Time Left: 174.0\n",
            "Epoch: 01/02 | Batch: 00119/01887 | Loss: 0.7075 | Avg Loss: 0.6851 | Prediction: 0.3741440176963806 | Label: 1 | Time: 0.008448 | Avg Time: 0.09758 | Time Left: 172.5\n",
            "Epoch: 01/02 | Batch: 00120/01887 | Loss: 0.7536 | Avg Loss: 0.6857 | Prediction: 0.36494359374046326 | Label: 0 | Time: 0.004771 | Avg Time: 0.09681 | Time Left: 171.1\n",
            "Epoch: 01/02 | Batch: 00121/01887 | Loss: 0.7295 | Avg Loss: 0.686 | Prediction: 0.37260669469833374 | Label: 1 | Time: 0.004695 | Avg Time: 0.09605 | Time Left: 169.6\n",
            "Epoch: 01/02 | Batch: 00122/01887 | Loss: 0.7055 | Avg Loss: 0.6862 | Prediction: 0.35724878311157227 | Label: 0 | Time: 0.004491 | Avg Time: 0.0953 | Time Left: 168.2\n",
            "Epoch: 01/02 | Batch: 00123/01887 | Loss: 0.7035 | Avg Loss: 0.6863 | Prediction: 0.33957213163375854 | Label: 0 | Time: 0.004623 | Avg Time: 0.09456 | Time Left: 166.8\n",
            "Epoch: 01/02 | Batch: 00124/01887 | Loss: 0.7423 | Avg Loss: 0.6868 | Prediction: 0.32245269417762756 | Label: 1 | Time: 0.005973 | Avg Time: 0.09384 | Time Left: 165.4\n",
            "Epoch: 01/02 | Batch: 00125/01887 | Loss: 0.7372 | Avg Loss: 0.6872 | Prediction: 0.29918941855430603 | Label: 1 | Time: 0.009728 | Avg Time: 0.09317 | Time Left: 164.2\n",
            "Epoch: 01/02 | Batch: 00126/01887 | Loss: 0.6831 | Avg Loss: 0.6872 | Prediction: 0.2761914134025574 | Label: 1 | Time: 0.00623 | Avg Time: 0.09248 | Time Left: 162.9\n",
            "Epoch: 01/02 | Batch: 00127/01887 | Loss: 0.6677 | Avg Loss: 0.687 | Prediction: 0.2563023567199707 | Label: 1 | Time: 0.006101 | Avg Time: 0.0918 | Time Left: 161.6\n",
            "Epoch: 01/02 | Batch: 00128/01887 | Loss: 0.6236 | Avg Loss: 0.6865 | Prediction: 0.24190255999565125 | Label: 1 | Time: 0.006678 | Avg Time: 0.09114 | Time Left: 160.3\n",
            "Epoch: 01/02 | Batch: 00129/01887 | Loss: 0.6543 | Avg Loss: 0.6863 | Prediction: 0.23277369141578674 | Label: 0 | Time: 0.01155 | Avg Time: 0.09052 | Time Left: 159.1\n",
            "Epoch: 01/02 | Batch: 00130/01887 | Loss: 0.6258 | Avg Loss: 0.6858 | Prediction: 0.23127540946006775 | Label: 1 | Time: 0.009726 | Avg Time: 0.0899 | Time Left: 157.9\n",
            "Epoch: 01/02 | Batch: 00131/01887 | Loss: 0.6677 | Avg Loss: 0.6857 | Prediction: 0.23404082655906677 | Label: 1 | Time: 0.00495 | Avg Time: 0.08925 | Time Left: 156.7\n",
            "Epoch: 01/02 | Batch: 00132/01887 | Loss: 0.6538 | Avg Loss: 0.6854 | Prediction: 0.23614737391471863 | Label: 1 | Time: 0.01098 | Avg Time: 0.08866 | Time Left: 155.6\n",
            "Epoch: 01/02 | Batch: 00133/01887 | Loss: 0.6671 | Avg Loss: 0.6853 | Prediction: 0.24213258922100067 | Label: 1 | Time: 0.008085 | Avg Time: 0.08805 | Time Left: 154.4\n",
            "Epoch: 01/02 | Batch: 00134/01887 | Loss: 0.6981 | Avg Loss: 0.6854 | Prediction: 0.24986255168914795 | Label: 1 | Time: 0.007559 | Avg Time: 0.08745 | Time Left: 153.3\n",
            "Epoch: 01/02 | Batch: 00135/01887 | Loss: 0.6821 | Avg Loss: 0.6853 | Prediction: 0.23384034633636475 | Label: 0 | Time: 0.009352 | Avg Time: 0.08687 | Time Left: 152.2\n",
            "Epoch: 01/02 | Batch: 00136/01887 | Loss: 0.6515 | Avg Loss: 0.6851 | Prediction: 0.25509241223335266 | Label: 0 | Time: 0.01343 | Avg Time: 0.08633 | Time Left: 151.2\n",
            "Epoch: 01/02 | Batch: 00137/01887 | Loss: 0.6799 | Avg Loss: 0.6851 | Prediction: 0.268218070268631 | Label: 1 | Time: 0.007401 | Avg Time: 0.08575 | Time Left: 150.1\n",
            "Epoch: 01/02 | Batch: 00138/01887 | Loss: 0.6475 | Avg Loss: 0.6848 | Prediction: 0.26915687322616577 | Label: 0 | Time: 0.004719 | Avg Time: 0.08517 | Time Left: 149.0\n",
            "Epoch: 01/02 | Batch: 00139/01887 | Loss: 0.6998 | Avg Loss: 0.6849 | Prediction: 0.2874484360218048 | Label: 1 | Time: 0.007779 | Avg Time: 0.08461 | Time Left: 147.9\n",
            "Epoch: 01/02 | Batch: 00140/01887 | Loss: 0.7147 | Avg Loss: 0.6851 | Prediction: 0.296951562166214 | Label: 1 | Time: 0.006145 | Avg Time: 0.08405 | Time Left: 146.8\n",
            "Epoch: 01/02 | Batch: 00141/01887 | Loss: 0.6797 | Avg Loss: 0.6851 | Prediction: 0.301537424325943 | Label: 1 | Time: 0.006365 | Avg Time: 0.0835 | Time Left: 145.8\n",
            "Epoch: 01/02 | Batch: 00142/01887 | Loss: 0.6633 | Avg Loss: 0.6849 | Prediction: 0.3058258593082428 | Label: 0 | Time: 0.005392 | Avg Time: 0.08295 | Time Left: 144.7\n",
            "Epoch: 01/02 | Batch: 00143/01887 | Loss: 0.6796 | Avg Loss: 0.6849 | Prediction: 0.31612589955329895 | Label: 1 | Time: 0.01347 | Avg Time: 0.08246 | Time Left: 143.8\n",
            "Epoch: 01/02 | Batch: 00144/01887 | Loss: 0.6592 | Avg Loss: 0.6847 | Prediction: 0.3203425109386444 | Label: 1 | Time: 0.006986 | Avg Time: 0.08194 | Time Left: 142.8\n",
            "Epoch: 01/02 | Batch: 00145/01887 | Loss: 0.6974 | Avg Loss: 0.6848 | Prediction: 0.3011999726295471 | Label: 0 | Time: 0.009747 | Avg Time: 0.08144 | Time Left: 141.9\n",
            "Epoch: 01/02 | Batch: 00146/01887 | Loss: 0.6993 | Avg Loss: 0.6849 | Prediction: 0.32522568106651306 | Label: 0 | Time: 0.004454 | Avg Time: 0.08091 | Time Left: 140.9\n",
            "Epoch: 01/02 | Batch: 00147/01887 | Loss: 0.6761 | Avg Loss: 0.6848 | Prediction: 0.33839017152786255 | Label: 1 | Time: 0.01518 | Avg Time: 0.08047 | Time Left: 140.0\n",
            "Epoch: 01/02 | Batch: 00148/01887 | Loss: 0.6953 | Avg Loss: 0.6849 | Prediction: 0.34106165170669556 | Label: 1 | Time: 0.01387 | Avg Time: 0.08002 | Time Left: 139.1\n",
            "Epoch: 01/02 | Batch: 00149/01887 | Loss: 0.7622 | Avg Loss: 0.6854 | Prediction: 0.3393874168395996 | Label: 0 | Time: 0.007191 | Avg Time: 0.07953 | Time Left: 138.2\n",
            "Epoch: 01/02 | Batch: 00150/01887 | Loss: 0.6415 | Avg Loss: 0.6851 | Prediction: 0.3309237062931061 | Label: 1 | Time: 0.007722 | Avg Time: 0.07905 | Time Left: 137.3\n",
            "Epoch: 01/02 | Batch: 00151/01887 | Loss: 0.695 | Avg Loss: 0.6852 | Prediction: 0.31722748279571533 | Label: 1 | Time: 0.005538 | Avg Time: 0.07856 | Time Left: 136.4\n",
            "Epoch: 01/02 | Batch: 00152/01887 | Loss: 0.6734 | Avg Loss: 0.6851 | Prediction: 0.23824083805084229 | Label: 0 | Time: 0.0104 | Avg Time: 0.07811 | Time Left: 135.5\n",
            "Epoch: 01/02 | Batch: 00153/01887 | Loss: 0.6921 | Avg Loss: 0.6852 | Prediction: 0.2899192273616791 | Label: 0 | Time: 0.004822 | Avg Time: 0.07763 | Time Left: 134.6\n",
            "Epoch: 01/02 | Batch: 00154/01887 | Loss: 0.6848 | Avg Loss: 0.6852 | Prediction: 0.24850288033485413 | Label: 0 | Time: 0.006459 | Avg Time: 0.07717 | Time Left: 133.7\n",
            "Epoch: 01/02 | Batch: 00155/01887 | Loss: 0.6719 | Avg Loss: 0.6851 | Prediction: 0.2790103852748871 | Label: 1 | Time: 0.004851 | Avg Time: 0.07671 | Time Left: 132.9\n",
            "Epoch: 01/02 | Batch: 00156/01887 | Loss: 0.6104 | Avg Loss: 0.6846 | Prediction: 0.27207836508750916 | Label: 1 | Time: 0.01065 | Avg Time: 0.07628 | Time Left: 132.0\n",
            "Epoch: 01/02 | Batch: 00157/01887 | Loss: 0.6094 | Avg Loss: 0.6841 | Prediction: 0.2802146077156067 | Label: 1 | Time: 0.004814 | Avg Time: 0.07583 | Time Left: 131.2\n",
            "Epoch: 01/02 | Batch: 00158/01887 | Loss: 0.6569 | Avg Loss: 0.6839 | Prediction: 0.30212703347206116 | Label: 1 | Time: 0.008454 | Avg Time: 0.0754 | Time Left: 130.4\n",
            "Epoch: 01/02 | Batch: 00159/01887 | Loss: 0.6307 | Avg Loss: 0.6836 | Prediction: 0.32741987705230713 | Label: 1 | Time: 0.004572 | Avg Time: 0.07496 | Time Left: 129.5\n",
            "Epoch: 01/02 | Batch: 00160/01887 | Loss: 0.6757 | Avg Loss: 0.6836 | Prediction: 0.37889784574508667 | Label: 1 | Time: 0.007367 | Avg Time: 0.07453 | Time Left: 128.7\n",
            "Epoch: 01/02 | Batch: 00161/01887 | Loss: 0.6305 | Avg Loss: 0.6832 | Prediction: 0.3992202877998352 | Label: 0 | Time: 0.01344 | Avg Time: 0.07415 | Time Left: 128.0\n",
            "Epoch: 01/02 | Batch: 00162/01887 | Loss: 0.6176 | Avg Loss: 0.6828 | Prediction: 0.4652681052684784 | Label: 1 | Time: 0.004977 | Avg Time: 0.07373 | Time Left: 127.2\n",
            "Epoch: 01/02 | Batch: 00163/01887 | Loss: 0.5852 | Avg Loss: 0.6822 | Prediction: 0.534110426902771 | Label: 1 | Time: 0.01221 | Avg Time: 0.07335 | Time Left: 126.5\n",
            "Epoch: 01/02 | Batch: 00164/01887 | Loss: 0.5619 | Avg Loss: 0.6815 | Prediction: 0.4248742461204529 | Label: 0 | Time: 0.005783 | Avg Time: 0.07294 | Time Left: 125.7\n",
            "Epoch: 01/02 | Batch: 00165/01887 | Loss: 0.5793 | Avg Loss: 0.6809 | Prediction: 0.5318063497543335 | Label: 1 | Time: 0.007317 | Avg Time: 0.07254 | Time Left: 124.9\n",
            "Epoch: 01/02 | Batch: 00166/01887 | Loss: 0.6511 | Avg Loss: 0.6807 | Prediction: 0.9514629244804382 | Label: 1 | Time: 0.004228 | Avg Time: 0.07213 | Time Left: 124.1\n",
            "Epoch: 01/02 | Batch: 00167/01887 | Loss: 0.4846 | Avg Loss: 0.6795 | Prediction: 1.096303105354309 | Label: 1 | Time: 0.007514 | Avg Time: 0.07174 | Time Left: 123.4\n",
            "Epoch: 01/02 | Batch: 00168/01887 | Loss: 0.834 | Avg Loss: 0.6804 | Prediction: 1.3016068935394287 | Label: 1 | Time: 0.01156 | Avg Time: 0.07138 | Time Left: 122.7\n",
            "Epoch: 01/02 | Batch: 00169/01887 | Loss: 0.6426 | Avg Loss: 0.6802 | Prediction: 1.2762068510055542 | Label: 1 | Time: 0.01238 | Avg Time: 0.07103 | Time Left: 122.0\n",
            "Epoch: 01/02 | Batch: 00170/01887 | Loss: 0.6796 | Avg Loss: 0.6802 | Prediction: 0.9137479066848755 | Label: 0 | Time: 0.007011 | Avg Time: 0.07066 | Time Left: 121.3\n",
            "Epoch: 01/02 | Batch: 00171/01887 | Loss: 0.57 | Avg Loss: 0.6796 | Prediction: 0.6277393102645874 | Label: 0 | Time: 0.005681 | Avg Time: 0.07028 | Time Left: 120.6\n",
            "Epoch: 01/02 | Batch: 00172/01887 | Loss: 0.5343 | Avg Loss: 0.6787 | Prediction: 0.5436452627182007 | Label: 0 | Time: 0.004448 | Avg Time: 0.06989 | Time Left: 119.9\n",
            "Epoch: 01/02 | Batch: 00173/01887 | Loss: 0.5117 | Avg Loss: 0.6778 | Prediction: 0.25685036182403564 | Label: 0 | Time: 0.004329 | Avg Time: 0.06952 | Time Left: 119.1\n",
            "Epoch: 01/02 | Batch: 00174/01887 | Loss: 0.5725 | Avg Loss: 0.6771 | Prediction: 0.28781571984291077 | Label: 0 | Time: 0.004353 | Avg Time: 0.06914 | Time Left: 118.4\n",
            "Epoch: 01/02 | Batch: 00175/01887 | Loss: 0.6231 | Avg Loss: 0.6768 | Prediction: 0.1266106814146042 | Label: 0 | Time: 0.007332 | Avg Time: 0.06879 | Time Left: 117.8\n",
            "Epoch: 01/02 | Batch: 00176/01887 | Loss: 0.5977 | Avg Loss: 0.6764 | Prediction: -0.10545025020837784 | Label: 0 | Time: 0.004648 | Avg Time: 0.06842 | Time Left: 117.1\n",
            "Epoch: 01/02 | Batch: 00177/01887 | Loss: 0.5522 | Avg Loss: 0.6757 | Prediction: 0.6175394654273987 | Label: 1 | Time: 0.00703 | Avg Time: 0.06808 | Time Left: 116.4\n",
            "Epoch: 01/02 | Batch: 00178/01887 | Loss: 0.5972 | Avg Loss: 0.6752 | Prediction: -0.39599618315696716 | Label: 0 | Time: 0.009468 | Avg Time: 0.06775 | Time Left: 115.8\n",
            "Epoch: 01/02 | Batch: 00179/01887 | Loss: 0.5297 | Avg Loss: 0.6744 | Prediction: -0.5761891603469849 | Label: 0 | Time: 0.005125 | Avg Time: 0.0674 | Time Left: 115.1\n",
            "Epoch: 01/02 | Batch: 00180/01887 | Loss: 0.4886 | Avg Loss: 0.6734 | Prediction: -0.4062608480453491 | Label: 0 | Time: 0.004549 | Avg Time: 0.06705 | Time Left: 114.5\n",
            "Epoch: 01/02 | Batch: 00181/01887 | Loss: 0.471 | Avg Loss: 0.6723 | Prediction: 0.3565203547477722 | Label: 1 | Time: 0.008407 | Avg Time: 0.06672 | Time Left: 113.8\n",
            "Epoch: 01/02 | Batch: 00182/01887 | Loss: 0.4966 | Avg Loss: 0.6713 | Prediction: -1.2883243560791016 | Label: 0 | Time: 0.004344 | Avg Time: 0.06638 | Time Left: 113.2\n",
            "Epoch: 01/02 | Batch: 00183/01887 | Loss: 0.5705 | Avg Loss: 0.6708 | Prediction: 0.49754443764686584 | Label: 1 | Time: 0.005488 | Avg Time: 0.06605 | Time Left: 112.5\n",
            "Epoch: 01/02 | Batch: 00184/01887 | Loss: 0.4883 | Avg Loss: 0.6698 | Prediction: -0.4083603024482727 | Label: 1 | Time: 0.004611 | Avg Time: 0.06571 | Time Left: 111.9\n",
            "Epoch: 01/02 | Batch: 00185/01887 | Loss: 0.487 | Avg Loss: 0.6688 | Prediction: 0.2086685746908188 | Label: 0 | Time: 0.008075 | Avg Time: 0.0654 | Time Left: 111.3\n",
            "Epoch: 01/02 | Batch: 00186/01887 | Loss: 0.357 | Avg Loss: 0.6671 | Prediction: 0.6271139979362488 | Label: 1 | Time: 0.004454 | Avg Time: 0.06508 | Time Left: 110.7\n",
            "Epoch: 01/02 | Batch: 00187/01887 | Loss: 0.4827 | Avg Loss: 0.6661 | Prediction: 0.9819307327270508 | Label: 1 | Time: 0.005572 | Avg Time: 0.06476 | Time Left: 110.1\n",
            "Epoch: 01/02 | Batch: 00188/01887 | Loss: 0.3913 | Avg Loss: 0.6647 | Prediction: -1.3709030151367188 | Label: 0 | Time: 0.01133 | Avg Time: 0.06447 | Time Left: 109.5\n",
            "Epoch: 01/02 | Batch: 00189/01887 | Loss: 0.1011 | Avg Loss: 0.6617 | Prediction: 1.9614452123641968 | Label: 1 | Time: 0.004519 | Avg Time: 0.06416 | Time Left: 108.9\n",
            "Epoch: 01/02 | Batch: 00190/01887 | Loss: 0.1071 | Avg Loss: 0.6588 | Prediction: -4.383706569671631 | Label: 0 | Time: 0.006102 | Avg Time: 0.06385 | Time Left: 108.4\n",
            "Epoch: 01/02 | Batch: 00191/01887 | Loss: 0.5183 | Avg Loss: 0.658 | Prediction: 3.2257471084594727 | Label: 1 | Time: 0.01213 | Avg Time: 0.06358 | Time Left: 107.8\n",
            "Epoch: 01/02 | Batch: 00192/01887 | Loss: 0.2029 | Avg Loss: 0.6557 | Prediction: 2.8594400882720947 | Label: 1 | Time: 0.004403 | Avg Time: 0.06327 | Time Left: 107.2\n",
            "Epoch: 01/02 | Batch: 00193/01887 | Loss: 0.4735 | Avg Loss: 0.6547 | Prediction: 2.3460402488708496 | Label: 1 | Time: 0.006241 | Avg Time: 0.06298 | Time Left: 106.7\n",
            "Epoch: 01/02 | Batch: 00194/01887 | Loss: 0.06628 | Avg Loss: 0.6517 | Prediction: -7.175601959228516 | Label: 0 | Time: 0.01256 | Avg Time: 0.06272 | Time Left: 106.2\n",
            "Epoch: 01/02 | Batch: 00195/01887 | Loss: 0.06771 | Avg Loss: 0.6487 | Prediction: 2.4711432456970215 | Label: 1 | Time: 0.01738 | Avg Time: 0.06248 | Time Left: 105.7\n",
            "Epoch: 01/02 | Batch: 00196/01887 | Loss: 0.3398 | Avg Loss: 0.6471 | Prediction: -7.513646602630615 | Label: 0 | Time: 0.004789 | Avg Time: 0.06219 | Time Left: 105.2\n",
            "Epoch: 01/02 | Batch: 00197/01887 | Loss: 0.281 | Avg Loss: 0.6453 | Prediction: -1.7030165195465088 | Label: 0 | Time: 0.007252 | Avg Time: 0.06191 | Time Left: 104.6\n",
            "Epoch: 01/02 | Batch: 00198/01887 | Loss: 0.1771 | Avg Loss: 0.6429 | Prediction: -7.889101505279541 | Label: 0 | Time: 0.004404 | Avg Time: 0.06162 | Time Left: 104.1\n",
            "Epoch: 01/02 | Batch: 00199/01887 | Loss: 0.1058 | Avg Loss: 0.6402 | Prediction: -3.605468511581421 | Label: 0 | Time: 0.01988 | Avg Time: 0.06141 | Time Left: 103.7\n",
            "Epoch: 01/02 | Batch: 00200/01887 | Loss: 0.0707 | Avg Loss: 0.6373 | Prediction: 1.9309405088424683 | Label: 1 | Time: 0.01047 | Avg Time: 0.06116 | Time Left: 103.2\n",
            "Epoch: 01/02 | Batch: 00201/01887 | Loss: 0.05016 | Avg Loss: 0.6344 | Prediction: 2.673752784729004 | Label: 1 | Time: 0.0114 | Avg Time: 0.06091 | Time Left: 102.7\n",
            "Epoch: 01/02 | Batch: 00202/01887 | Loss: 0.03439 | Avg Loss: 0.6314 | Prediction: -9.46742057800293 | Label: 0 | Time: 0.007083 | Avg Time: 0.06064 | Time Left: 102.2\n",
            "Epoch: 01/02 | Batch: 00203/01887 | Loss: 0.01439 | Avg Loss: 0.6284 | Prediction: 3.5221381187438965 | Label: 1 | Time: 0.005298 | Avg Time: 0.06037 | Time Left: 101.7\n",
            "Epoch: 01/02 | Batch: 00204/01887 | Loss: 0.3266 | Avg Loss: 0.6269 | Prediction: 4.515518665313721 | Label: 1 | Time: 0.02357 | Avg Time: 0.06019 | Time Left: 101.3\n",
            "Epoch: 01/02 | Batch: 00205/01887 | Loss: 0.1872 | Avg Loss: 0.6248 | Prediction: -6.225749969482422 | Label: 0 | Time: 0.004744 | Avg Time: 0.05992 | Time Left: 100.8\n",
            "Epoch: 01/02 | Batch: 00206/01887 | Loss: 0.2677 | Avg Loss: 0.6231 | Prediction: -3.5609586238861084 | Label: 0 | Time: 0.01396 | Avg Time: 0.05969 | Time Left: 100.3\n",
            "Epoch: 01/02 | Batch: 00207/01887 | Loss: 0.1331 | Avg Loss: 0.6207 | Prediction: 1.7697652578353882 | Label: 1 | Time: 0.004419 | Avg Time: 0.05943 | Time Left: 99.84\n",
            "Epoch: 01/02 | Batch: 00208/01887 | Loss: 0.1749 | Avg Loss: 0.6185 | Prediction: 1.1846493482589722 | Label: 1 | Time: 0.02937 | Avg Time: 0.05928 | Time Left: 99.54\n",
            "Epoch: 01/02 | Batch: 00209/01887 | Loss: 0.1305 | Avg Loss: 0.6162 | Prediction: 1.513714075088501 | Label: 1 | Time: 0.0122 | Avg Time: 0.05906 | Time Left: 99.1\n",
            "Epoch: 01/02 | Batch: 00210/01887 | Loss: 0.2525 | Avg Loss: 0.6145 | Prediction: 2.984652519226074 | Label: 1 | Time: 0.007656 | Avg Time: 0.05881 | Time Left: 98.63\n",
            "Epoch: 01/02 | Batch: 00211/01887 | Loss: 0.1413 | Avg Loss: 0.6122 | Prediction: -1.505360722541809 | Label: 0 | Time: 0.005333 | Avg Time: 0.05856 | Time Left: 98.15\n",
            "Epoch: 01/02 | Batch: 00212/01887 | Loss: 0.1351 | Avg Loss: 0.61 | Prediction: 4.713379859924316 | Label: 1 | Time: 0.02031 | Avg Time: 0.05838 | Time Left: 97.79\n",
            "Epoch: 01/02 | Batch: 00213/01887 | Loss: 0.116 | Avg Loss: 0.6077 | Prediction: 4.030958652496338 | Label: 1 | Time: 0.00868 | Avg Time: 0.05815 | Time Left: 97.34\n",
            "Epoch: 01/02 | Batch: 00214/01887 | Loss: 0.2048 | Avg Loss: 0.6058 | Prediction: 3.379281759262085 | Label: 1 | Time: 0.01479 | Avg Time: 0.05794 | Time Left: 96.94\n",
            "Epoch: 01/02 | Batch: 00215/01887 | Loss: 0.09683 | Avg Loss: 0.6034 | Prediction: 2.8917462825775146 | Label: 1 | Time: 0.01164 | Avg Time: 0.05773 | Time Left: 96.52\n",
            "Epoch: 01/02 | Batch: 00216/01887 | Loss: 0.2293 | Avg Loss: 0.6017 | Prediction: 2.652287006378174 | Label: 0 | Time: 0.01626 | Avg Time: 0.05754 | Time Left: 96.14\n",
            "Epoch: 01/02 | Batch: 00217/01887 | Loss: 0.1719 | Avg Loss: 0.5997 | Prediction: -14.228119850158691 | Label: 0 | Time: 0.0118 | Avg Time: 0.05733 | Time Left: 95.73\n",
            "Epoch: 01/02 | Batch: 00218/01887 | Loss: 0.1863 | Avg Loss: 0.5978 | Prediction: -10.623127937316895 | Label: 0 | Time: 0.02306 | Avg Time: 0.05717 | Time Left: 95.41\n",
            "Epoch: 01/02 | Batch: 00219/01887 | Loss: 0.05765 | Avg Loss: 0.5953 | Prediction: 2.8225009441375732 | Label: 1 | Time: 0.01882 | Avg Time: 0.05699 | Time Left: 95.06\n",
            "Epoch: 01/02 | Batch: 00220/01887 | Loss: 0.0168 | Avg Loss: 0.5927 | Prediction: 3.849748373031616 | Label: 1 | Time: 0.01231 | Avg Time: 0.05679 | Time Left: 94.67\n",
            "Epoch: 01/02 | Batch: 00221/01887 | Loss: 0.1233 | Avg Loss: 0.5906 | Prediction: 5.301372051239014 | Label: 1 | Time: 0.01994 | Avg Time: 0.05662 | Time Left: 94.33\n",
            "Epoch: 01/02 | Batch: 00222/01887 | Loss: 0.00218 | Avg Loss: 0.5879 | Prediction: 5.6870293617248535 | Label: 1 | Time: 0.007491 | Avg Time: 0.0564 | Time Left: 93.91\n",
            "Epoch: 01/02 | Batch: 00223/01887 | Loss: 0.1138 | Avg Loss: 0.5858 | Prediction: 6.37162446975708 | Label: 1 | Time: 0.006277 | Avg Time: 0.05618 | Time Left: 93.48\n",
            "Epoch: 01/02 | Batch: 00224/01887 | Loss: 0.2854 | Avg Loss: 0.5845 | Prediction: -13.405353546142578 | Label: 0 | Time: 0.004902 | Avg Time: 0.05595 | Time Left: 93.04\n",
            "Epoch: 01/02 | Batch: 00225/01887 | Loss: 0.5295 | Avg Loss: 0.5842 | Prediction: 4.493330001831055 | Label: 1 | Time: 0.014 | Avg Time: 0.05576 | Time Left: 92.68\n",
            "Epoch: 01/02 | Batch: 00226/01887 | Loss: 0.05405 | Avg Loss: 0.5819 | Prediction: 2.6560118198394775 | Label: 1 | Time: 0.01261 | Avg Time: 0.05557 | Time Left: 92.3\n",
            "Epoch: 01/02 | Batch: 00227/01887 | Loss: 0.6751 | Avg Loss: 0.5823 | Prediction: -0.259845495223999 | Label: 1 | Time: 0.01136 | Avg Time: 0.05538 | Time Left: 91.92\n",
            "Epoch: 01/02 | Batch: 00228/01887 | Loss: 0.1338 | Avg Loss: 0.5803 | Prediction: -17.13060760498047 | Label: 0 | Time: 0.01418 | Avg Time: 0.0552 | Time Left: 91.57\n",
            "Epoch: 01/02 | Batch: 00229/01887 | Loss: 1.284 | Avg Loss: 0.5834 | Prediction: 2.7756001949310303 | Label: 1 | Time: 0.0156 | Avg Time: 0.05502 | Time Left: 91.23\n",
            "Epoch: 01/02 | Batch: 00230/01887 | Loss: 0.03151 | Avg Loss: 0.581 | Prediction: 4.239240646362305 | Label: 1 | Time: 0.009196 | Avg Time: 0.05482 | Time Left: 90.84\n",
            "Epoch: 01/02 | Batch: 00231/01887 | Loss: 1.027 | Avg Loss: 0.5829 | Prediction: 4.871214389801025 | Label: 1 | Time: 0.009305 | Avg Time: 0.05463 | Time Left: 90.46\n",
            "Epoch: 01/02 | Batch: 00232/01887 | Loss: 0.4861 | Avg Loss: 0.5825 | Prediction: 5.648712158203125 | Label: 1 | Time: 0.01467 | Avg Time: 0.05445 | Time Left: 90.12\n",
            "Epoch: 01/02 | Batch: 00233/01887 | Loss: 0.02149 | Avg Loss: 0.5801 | Prediction: -10.118549346923828 | Label: 0 | Time: 0.008867 | Avg Time: 0.05426 | Time Left: 89.74\n",
            "Epoch: 01/02 | Batch: 00234/01887 | Loss: 0.005328 | Avg Loss: 0.5776 | Prediction: 5.190553665161133 | Label: 1 | Time: 0.01131 | Avg Time: 0.05407 | Time Left: 89.39\n",
            "Epoch: 01/02 | Batch: 00235/01887 | Loss: 0.1845 | Avg Loss: 0.576 | Prediction: 4.966073513031006 | Label: 1 | Time: 0.0112 | Avg Time: 0.05389 | Time Left: 89.03\n",
            "Epoch: 01/02 | Batch: 00236/01887 | Loss: 0.009612 | Avg Loss: 0.5736 | Prediction: -5.533599376678467 | Label: 0 | Time: 0.005493 | Avg Time: 0.05369 | Time Left: 88.64\n",
            "Epoch: 01/02 | Batch: 00237/01887 | Loss: 0.2643 | Avg Loss: 0.5723 | Prediction: 4.7615251541137695 | Label: 1 | Time: 0.009373 | Avg Time: 0.0535 | Time Left: 88.28\n",
            "Epoch: 01/02 | Batch: 00238/01887 | Loss: 0.412 | Avg Loss: 0.5716 | Prediction: -6.852651596069336 | Label: 0 | Time: 0.008541 | Avg Time: 0.05331 | Time Left: 87.91\n",
            "Epoch: 01/02 | Batch: 00239/01887 | Loss: 0.02698 | Avg Loss: 0.5693 | Prediction: 3.3882198333740234 | Label: 1 | Time: 0.004506 | Avg Time: 0.05311 | Time Left: 87.52\n",
            "Epoch: 01/02 | Batch: 00240/01887 | Loss: 0.356 | Avg Loss: 0.5684 | Prediction: -7.299591064453125 | Label: 0 | Time: 0.01534 | Avg Time: 0.05295 | Time Left: 87.21\n",
            "Epoch: 01/02 | Batch: 00241/01887 | Loss: 0.4207 | Avg Loss: 0.5678 | Prediction: -7.57963752746582 | Label: 0 | Time: 0.005788 | Avg Time: 0.05275 | Time Left: 86.83\n",
            "Epoch: 01/02 | Batch: 00242/01887 | Loss: 0.06025 | Avg Loss: 0.5657 | Prediction: 2.3543624877929688 | Label: 1 | Time: 0.01053 | Avg Time: 0.05258 | Time Left: 86.49\n",
            "Epoch: 01/02 | Batch: 00243/01887 | Loss: 0.182 | Avg Loss: 0.5641 | Prediction: -6.7030181884765625 | Label: 0 | Time: 0.005423 | Avg Time: 0.05239 | Time Left: 86.12\n",
            "Epoch: 01/02 | Batch: 00244/01887 | Loss: 0.1692 | Avg Loss: 0.5625 | Prediction: 2.08911395072937 | Label: 1 | Time: 0.02035 | Avg Time: 0.05225 | Time Left: 85.85\n",
            "Epoch: 01/02 | Batch: 00245/01887 | Loss: 0.07764 | Avg Loss: 0.5605 | Prediction: 1.7754939794540405 | Label: 1 | Time: 0.01567 | Avg Time: 0.0521 | Time Left: 85.56\n",
            "Epoch: 01/02 | Batch: 00246/01887 | Loss: 0.1137 | Avg Loss: 0.5587 | Prediction: 1.7747578620910645 | Label: 1 | Time: 0.01066 | Avg Time: 0.05194 | Time Left: 85.23\n",
            "Epoch: 01/02 | Batch: 00247/01887 | Loss: 0.4167 | Avg Loss: 0.5581 | Prediction: -5.347152233123779 | Label: 1 | Time: 0.009356 | Avg Time: 0.05176 | Time Left: 84.89\n",
            "Epoch: 01/02 | Batch: 00248/01887 | Loss: 0.144 | Avg Loss: 0.5565 | Prediction: -5.495322227478027 | Label: 0 | Time: 0.01345 | Avg Time: 0.05161 | Time Left: 84.59\n",
            "Epoch: 01/02 | Batch: 00249/01887 | Loss: 0.2445 | Avg Loss: 0.5552 | Prediction: -5.2234320640563965 | Label: 0 | Time: 0.01384 | Avg Time: 0.05146 | Time Left: 84.29\n",
            "Epoch: 01/02 | Batch: 00250/01887 | Loss: 0.1593 | Avg Loss: 0.5536 | Prediction: 1.867734670639038 | Label: 1 | Time: 0.005533 | Avg Time: 0.05127 | Time Left: 83.94\n",
            "Epoch: 01/02 | Batch: 00251/01887 | Loss: 0.3357 | Avg Loss: 0.5528 | Prediction: 1.9410226345062256 | Label: 1 | Time: 0.004568 | Avg Time: 0.05109 | Time Left: 83.58\n",
            "Epoch: 01/02 | Batch: 00252/01887 | Loss: 0.07705 | Avg Loss: 0.5509 | Prediction: -5.870777606964111 | Label: 0 | Time: 0.0113 | Avg Time: 0.05093 | Time Left: 83.27\n",
            "Epoch: 01/02 | Batch: 00253/01887 | Loss: 0.05712 | Avg Loss: 0.5489 | Prediction: 2.35107421875 | Label: 1 | Time: 0.01162 | Avg Time: 0.05077 | Time Left: 82.97\n",
            "Epoch: 01/02 | Batch: 00254/01887 | Loss: 0.6318 | Avg Loss: 0.5493 | Prediction: -5.116609573364258 | Label: 0 | Time: 0.01089 | Avg Time: 0.05062 | Time Left: 82.66\n",
            "Epoch: 01/02 | Batch: 00255/01887 | Loss: 0.107 | Avg Loss: 0.5475 | Prediction: -3.750767469406128 | Label: 0 | Time: 0.00847 | Avg Time: 0.05045 | Time Left: 82.34\n",
            "Epoch: 01/02 | Batch: 00256/01887 | Loss: 0.2416 | Avg Loss: 0.5463 | Prediction: 3.2178823947906494 | Label: 1 | Time: 0.01205 | Avg Time: 0.0503 | Time Left: 82.04\n",
            "Epoch: 01/02 | Batch: 00257/01887 | Loss: 0.09714 | Avg Loss: 0.5446 | Prediction: -2.6489319801330566 | Label: 0 | Time: 0.004445 | Avg Time: 0.05012 | Time Left: 81.7\n",
            "Epoch: 01/02 | Batch: 00258/01887 | Loss: 0.2849 | Avg Loss: 0.5436 | Prediction: 3.398667812347412 | Label: 1 | Time: 0.01349 | Avg Time: 0.04998 | Time Left: 81.42\n",
            "Epoch: 01/02 | Batch: 00259/01887 | Loss: 0.1928 | Avg Loss: 0.5422 | Prediction: -2.2741706371307373 | Label: 0 | Time: 0.01723 | Avg Time: 0.04986 | Time Left: 81.16\n",
            "Epoch: 01/02 | Batch: 00260/01887 | Loss: 0.0971 | Avg Loss: 0.5405 | Prediction: -2.0134048461914062 | Label: 0 | Time: 0.0247 | Avg Time: 0.04976 | Time Left: 80.96\n",
            "Epoch: 01/02 | Batch: 00261/01887 | Loss: 0.2639 | Avg Loss: 0.5394 | Prediction: 3.4645535945892334 | Label: 1 | Time: 0.01442 | Avg Time: 0.04962 | Time Left: 80.69\n",
            "Epoch: 01/02 | Batch: 00262/01887 | Loss: 0.02386 | Avg Loss: 0.5375 | Prediction: 3.815467596054077 | Label: 1 | Time: 0.005512 | Avg Time: 0.04946 | Time Left: 80.36\n",
            "Epoch: 01/02 | Batch: 00263/01887 | Loss: 0.0564 | Avg Loss: 0.5356 | Prediction: -2.4962620735168457 | Label: 0 | Time: 0.006111 | Avg Time: 0.04929 | Time Left: 80.05\n",
            "Epoch: 01/02 | Batch: 00264/01887 | Loss: 0.4275 | Avg Loss: 0.5352 | Prediction: -4.645984649658203 | Label: 0 | Time: 0.006649 | Avg Time: 0.04913 | Time Left: 79.74\n",
            "Epoch: 01/02 | Batch: 00265/01887 | Loss: 0.3116 | Avg Loss: 0.5344 | Prediction: -1.3885215520858765 | Label: 0 | Time: 0.006788 | Avg Time: 0.04897 | Time Left: 79.43\n",
            "Epoch: 01/02 | Batch: 00266/01887 | Loss: 0.3481 | Avg Loss: 0.5337 | Prediction: -2.25783109664917 | Label: 0 | Time: 0.007212 | Avg Time: 0.04881 | Time Left: 79.12\n",
            "Epoch: 01/02 | Batch: 00267/01887 | Loss: 0.3237 | Avg Loss: 0.5329 | Prediction: -0.4004165530204773 | Label: 0 | Time: 0.02426 | Avg Time: 0.04872 | Time Left: 78.93\n",
            "Epoch: 01/02 | Batch: 00268/01887 | Loss: 0.4535 | Avg Loss: 0.5326 | Prediction: -1.193418025970459 | Label: 0 | Time: 0.004709 | Avg Time: 0.04856 | Time Left: 78.61\n",
            "Epoch: 01/02 | Batch: 00269/01887 | Loss: 0.07634 | Avg Loss: 0.5309 | Prediction: 3.0267276763916016 | Label: 1 | Time: 0.01324 | Avg Time: 0.04842 | Time Left: 78.35\n",
            "Epoch: 01/02 | Batch: 00270/01887 | Loss: 0.07382 | Avg Loss: 0.5292 | Prediction: -5.046117782592773 | Label: 0 | Time: 0.005959 | Avg Time: 0.04827 | Time Left: 78.05\n",
            "Epoch: 01/02 | Batch: 00271/01887 | Loss: 0.0614 | Avg Loss: 0.5275 | Prediction: -3.312972068786621 | Label: 0 | Time: 0.01646 | Avg Time: 0.04815 | Time Left: 77.81\n",
            "Epoch: 01/02 | Batch: 00272/01887 | Loss: 0.117 | Avg Loss: 0.526 | Prediction: 2.140885829925537 | Label: 1 | Time: 0.005592 | Avg Time: 0.04799 | Time Left: 77.51\n",
            "Epoch: 01/02 | Batch: 00273/01887 | Loss: 0.1101 | Avg Loss: 0.5245 | Prediction: 2.1187734603881836 | Label: 1 | Time: 0.01068 | Avg Time: 0.04786 | Time Left: 77.24\n",
            "Epoch: 01/02 | Batch: 00274/01887 | Loss: 0.1544 | Avg Loss: 0.5231 | Prediction: 2.0691728591918945 | Label: 1 | Time: 0.01209 | Avg Time: 0.04773 | Time Left: 76.98\n",
            "Epoch: 01/02 | Batch: 00275/01887 | Loss: 0.08343 | Avg Loss: 0.5215 | Prediction: 2.130563735961914 | Label: 1 | Time: 0.01042 | Avg Time: 0.04759 | Time Left: 76.72\n",
            "Epoch: 01/02 | Batch: 00276/01887 | Loss: 0.08752 | Avg Loss: 0.5199 | Prediction: 1.823029637336731 | Label: 1 | Time: 0.006538 | Avg Time: 0.04744 | Time Left: 76.43\n",
            "Epoch: 01/02 | Batch: 00277/01887 | Loss: 0.2054 | Avg Loss: 0.5188 | Prediction: -4.967792987823486 | Label: 0 | Time: 0.009732 | Avg Time: 0.04731 | Time Left: 76.16\n",
            "Epoch: 01/02 | Batch: 00278/01887 | Loss: 0.131 | Avg Loss: 0.5174 | Prediction: 2.0678327083587646 | Label: 1 | Time: 0.005075 | Avg Time: 0.04715 | Time Left: 75.87\n",
            "Epoch: 01/02 | Batch: 00279/01887 | Loss: 0.08065 | Avg Loss: 0.5158 | Prediction: 2.100497245788574 | Label: 1 | Time: 0.006792 | Avg Time: 0.04701 | Time Left: 75.59\n",
            "Epoch: 01/02 | Batch: 00280/01887 | Loss: 0.06741 | Avg Loss: 0.5142 | Prediction: 2.0449516773223877 | Label: 1 | Time: 0.007938 | Avg Time: 0.04687 | Time Left: 75.32\n",
            "Epoch: 01/02 | Batch: 00281/01887 | Loss: 0.1608 | Avg Loss: 0.513 | Prediction: 2.2364323139190674 | Label: 1 | Time: 0.004456 | Avg Time: 0.04672 | Time Left: 75.03\n",
            "Epoch: 01/02 | Batch: 00282/01887 | Loss: 0.03244 | Avg Loss: 0.5113 | Prediction: -7.756536483764648 | Label: 0 | Time: 0.004315 | Avg Time: 0.04657 | Time Left: 74.74\n",
            "Epoch: 01/02 | Batch: 00283/01887 | Loss: 0.4396 | Avg Loss: 0.511 | Prediction: 2.449493646621704 | Label: 1 | Time: 0.005512 | Avg Time: 0.04642 | Time Left: 74.46\n",
            "Epoch: 01/02 | Batch: 00284/01887 | Loss: 0.1512 | Avg Loss: 0.5098 | Prediction: -4.5856828689575195 | Label: 0 | Time: 0.005791 | Avg Time: 0.04628 | Time Left: 74.19\n",
            "Epoch: 01/02 | Batch: 00285/01887 | Loss: 0.02306 | Avg Loss: 0.5081 | Prediction: 3.3957149982452393 | Label: 1 | Time: 0.01623 | Avg Time: 0.04617 | Time Left: 73.97\n",
            "Epoch: 01/02 | Batch: 00286/01887 | Loss: 0.09542 | Avg Loss: 0.5066 | Prediction: 0.5556167364120483 | Label: 0 | Time: 0.00477 | Avg Time: 0.04603 | Time Left: 73.69\n",
            "Epoch: 01/02 | Batch: 00287/01887 | Loss: 0.02905 | Avg Loss: 0.5049 | Prediction: 3.2888267040252686 | Label: 1 | Time: 0.008191 | Avg Time: 0.0459 | Time Left: 73.44\n",
            "Epoch: 01/02 | Batch: 00288/01887 | Loss: 0.03688 | Avg Loss: 0.5033 | Prediction: 3.3639891147613525 | Label: 1 | Time: 0.006083 | Avg Time: 0.04576 | Time Left: 73.17\n",
            "Epoch: 01/02 | Batch: 00289/01887 | Loss: 0.01638 | Avg Loss: 0.5016 | Prediction: 3.9922757148742676 | Label: 1 | Time: 0.01175 | Avg Time: 0.04564 | Time Left: 72.94\n",
            "Epoch: 01/02 | Batch: 00290/01887 | Loss: 0.01613 | Avg Loss: 0.5 | Prediction: 4.194729328155518 | Label: 1 | Time: 0.00463 | Avg Time: 0.0455 | Time Left: 72.66\n",
            "Epoch: 01/02 | Batch: 00291/01887 | Loss: 0.2179 | Avg Loss: 0.499 | Prediction: -5.0258073806762695 | Label: 0 | Time: 0.005678 | Avg Time: 0.04536 | Time Left: 72.4\n",
            "Epoch: 01/02 | Batch: 00292/01887 | Loss: 0.01506 | Avg Loss: 0.4973 | Prediction: -8.717878341674805 | Label: 0 | Time: 0.01184 | Avg Time: 0.04525 | Time Left: 72.17\n",
            "Epoch: 01/02 | Batch: 00293/01887 | Loss: 0.1743 | Avg Loss: 0.4962 | Prediction: -8.380155563354492 | Label: 0 | Time: 0.0136 | Avg Time: 0.04514 | Time Left: 71.95\n",
            "Epoch: 01/02 | Batch: 00294/01887 | Loss: 0.009182 | Avg Loss: 0.4946 | Prediction: -7.657992362976074 | Label: 0 | Time: 0.009042 | Avg Time: 0.04502 | Time Left: 71.71\n",
            "Epoch: 01/02 | Batch: 00295/01887 | Loss: 0.3432 | Avg Loss: 0.4941 | Prediction: -9.674455642700195 | Label: 0 | Time: 0.02101 | Avg Time: 0.04494 | Time Left: 71.54\n",
            "Epoch: 01/02 | Batch: 00296/01887 | Loss: 0.07156 | Avg Loss: 0.4926 | Prediction: -1.4553067684173584 | Label: 0 | Time: 0.01842 | Avg Time: 0.04485 | Time Left: 71.35\n",
            "Epoch: 01/02 | Batch: 00297/01887 | Loss: 0.08493 | Avg Loss: 0.4913 | Prediction: 3.418524980545044 | Label: 1 | Time: 0.006282 | Avg Time: 0.04472 | Time Left: 71.1\n",
            "Epoch: 01/02 | Batch: 00298/01887 | Loss: 0.08644 | Avg Loss: 0.4899 | Prediction: -0.5290549397468567 | Label: 0 | Time: 0.01494 | Avg Time: 0.04462 | Time Left: 70.9\n",
            "Epoch: 01/02 | Batch: 00299/01887 | Loss: 0.0677 | Avg Loss: 0.4885 | Prediction: 2.5072708129882812 | Label: 1 | Time: 0.005674 | Avg Time: 0.04449 | Time Left: 70.65\n",
            "Epoch: 01/02 | Batch: 00300/01887 | Loss: 0.6453 | Avg Loss: 0.489 | Prediction: -9.408060073852539 | Label: 0 | Time: 0.02215 | Avg Time: 0.04441 | Time Left: 70.48\n",
            "Epoch: 01/02 | Batch: 00301/01887 | Loss: 0.08809 | Avg Loss: 0.4877 | Prediction: -3.312731981277466 | Label: 0 | Time: 0.007273 | Avg Time: 0.04429 | Time Left: 70.24\n",
            "Epoch: 01/02 | Batch: 00302/01887 | Loss: 0.08151 | Avg Loss: 0.4863 | Prediction: -10.86674690246582 | Label: 0 | Time: 0.01875 | Avg Time: 0.0442 | Time Left: 70.06\n",
            "Epoch: 01/02 | Batch: 00303/01887 | Loss: 0.1808 | Avg Loss: 0.4853 | Prediction: 2.8614509105682373 | Label: 1 | Time: 0.008405 | Avg Time: 0.04409 | Time Left: 69.83\n",
            "Epoch: 01/02 | Batch: 00304/01887 | Loss: 0.04201 | Avg Loss: 0.4839 | Prediction: -11.185745239257812 | Label: 0 | Time: 0.01758 | Avg Time: 0.044 | Time Left: 69.65\n",
            "Epoch: 01/02 | Batch: 00305/01887 | Loss: 0.09145 | Avg Loss: 0.4826 | Prediction: -6.221365451812744 | Label: 0 | Time: 0.008311 | Avg Time: 0.04388 | Time Left: 69.42\n",
            "Epoch: 01/02 | Batch: 00306/01887 | Loss: 0.1442 | Avg Loss: 0.4815 | Prediction: -5.241116523742676 | Label: 0 | Time: 0.01987 | Avg Time: 0.0438 | Time Left: 69.25\n",
            "Epoch: 01/02 | Batch: 00307/01887 | Loss: 0.0254 | Avg Loss: 0.48 | Prediction: 3.486950397491455 | Label: 1 | Time: 0.01499 | Avg Time: 0.04371 | Time Left: 69.06\n",
            "Epoch: 01/02 | Batch: 00308/01887 | Loss: 0.2987 | Avg Loss: 0.4794 | Prediction: 3.5738933086395264 | Label: 1 | Time: 0.02438 | Avg Time: 0.04365 | Time Left: 68.92\n",
            "Epoch: 01/02 | Batch: 00309/01887 | Loss: 1.055 | Avg Loss: 0.4813 | Prediction: 1.3798238039016724 | Label: 0 | Time: 0.009344 | Avg Time: 0.04354 | Time Left: 68.7\n",
            "Epoch: 01/02 | Batch: 00310/01887 | Loss: 0.06798 | Avg Loss: 0.4799 | Prediction: -12.508990287780762 | Label: 0 | Time: 0.004599 | Avg Time: 0.04341 | Time Left: 68.46\n",
            "Epoch: 01/02 | Batch: 00311/01887 | Loss: 0.04535 | Avg Loss: 0.4785 | Prediction: -12.397936820983887 | Label: 0 | Time: 0.02438 | Avg Time: 0.04335 | Time Left: 68.32\n",
            "Epoch: 01/02 | Batch: 00312/01887 | Loss: 0.6222 | Avg Loss: 0.479 | Prediction: -10.349102020263672 | Label: 0 | Time: 0.03404 | Avg Time: 0.04332 | Time Left: 68.23\n",
            "Epoch: 01/02 | Batch: 00313/01887 | Loss: 0.7062 | Avg Loss: 0.4797 | Prediction: 2.810598373413086 | Label: 1 | Time: 0.008669 | Avg Time: 0.04321 | Time Left: 68.01\n",
            "Epoch: 01/02 | Batch: 00314/01887 | Loss: 0.2241 | Avg Loss: 0.4789 | Prediction: 2.5175347328186035 | Label: 1 | Time: 0.00443 | Avg Time: 0.04309 | Time Left: 67.77\n",
            "Epoch: 01/02 | Batch: 00315/01887 | Loss: 0.04735 | Avg Loss: 0.4775 | Prediction: 2.4731478691101074 | Label: 1 | Time: 0.02737 | Avg Time: 0.04304 | Time Left: 67.65\n",
            "Epoch: 01/02 | Batch: 00316/01887 | Loss: 0.05801 | Avg Loss: 0.4762 | Prediction: 3.0197792053222656 | Label: 1 | Time: 0.01543 | Avg Time: 0.04295 | Time Left: 67.47\n",
            "Epoch: 01/02 | Batch: 00317/01887 | Loss: 0.02709 | Avg Loss: 0.4748 | Prediction: 3.008315086364746 | Label: 1 | Time: 0.006147 | Avg Time: 0.04283 | Time Left: 67.25\n",
            "Epoch: 01/02 | Batch: 00318/01887 | Loss: 0.02773 | Avg Loss: 0.4734 | Prediction: -7.535999774932861 | Label: 0 | Time: 0.01552 | Avg Time: 0.04275 | Time Left: 67.07\n",
            "Epoch: 01/02 | Batch: 00319/01887 | Loss: 0.02174 | Avg Loss: 0.472 | Prediction: -4.414525032043457 | Label: 0 | Time: 0.004895 | Avg Time: 0.04263 | Time Left: 66.84\n",
            "Epoch: 01/02 | Batch: 00320/01887 | Loss: 0.4732 | Avg Loss: 0.472 | Prediction: 3.4399094581604004 | Label: 1 | Time: 0.01955 | Avg Time: 0.04256 | Time Left: 66.68\n",
            "Epoch: 01/02 | Batch: 00321/01887 | Loss: 0.02759 | Avg Loss: 0.4706 | Prediction: -2.2310540676116943 | Label: 0 | Time: 0.008673 | Avg Time: 0.04245 | Time Left: 66.48\n",
            "Epoch: 01/02 | Batch: 00322/01887 | Loss: 0.1959 | Avg Loss: 0.4697 | Prediction: 3.8366613388061523 | Label: 1 | Time: 0.004655 | Avg Time: 0.04233 | Time Left: 66.25\n",
            "Epoch: 01/02 | Batch: 00323/01887 | Loss: 0.1433 | Avg Loss: 0.4687 | Prediction: -3.9971349239349365 | Label: 0 | Time: 0.004777 | Avg Time: 0.04222 | Time Left: 66.03\n",
            "Epoch: 01/02 | Batch: 00324/01887 | Loss: 0.1637 | Avg Loss: 0.4678 | Prediction: -6.909806251525879 | Label: 0 | Time: 0.004126 | Avg Time: 0.0421 | Time Left: 65.8\n",
            "Epoch: 01/02 | Batch: 00325/01887 | Loss: 0.02249 | Avg Loss: 0.4664 | Prediction: 3.8799729347229004 | Label: 1 | Time: 0.004096 | Avg Time: 0.04198 | Time Left: 65.58\n",
            "Epoch: 01/02 | Batch: 00326/01887 | Loss: 0.07902 | Avg Loss: 0.4652 | Prediction: 3.106078624725342 | Label: 1 | Time: 0.01083 | Avg Time: 0.04189 | Time Left: 65.38\n",
            "Epoch: 01/02 | Batch: 00327/01887 | Loss: 0.03254 | Avg Loss: 0.4639 | Prediction: 3.610077381134033 | Label: 1 | Time: 0.02119 | Avg Time: 0.04182 | Time Left: 65.24\n",
            "Epoch: 01/02 | Batch: 00328/01887 | Loss: 0.3876 | Avg Loss: 0.4637 | Prediction: 3.4938230514526367 | Label: 1 | Time: 0.01545 | Avg Time: 0.04174 | Time Left: 65.08\n",
            "Epoch: 01/02 | Batch: 00329/01887 | Loss: 0.1532 | Avg Loss: 0.4627 | Prediction: 2.929143190383911 | Label: 1 | Time: 0.004214 | Avg Time: 0.04163 | Time Left: 64.86\n",
            "Epoch: 01/02 | Batch: 00330/01887 | Loss: 0.03452 | Avg Loss: 0.4614 | Prediction: 2.7386200428009033 | Label: 1 | Time: 0.00625 | Avg Time: 0.04152 | Time Left: 64.65\n",
            "Epoch: 01/02 | Batch: 00331/01887 | Loss: 0.07172 | Avg Loss: 0.4603 | Prediction: 2.6105024814605713 | Label: 1 | Time: 0.01937 | Avg Time: 0.04145 | Time Left: 64.5\n",
            "Epoch: 01/02 | Batch: 00332/01887 | Loss: 0.06115 | Avg Loss: 0.4591 | Prediction: 2.6082847118377686 | Label: 1 | Time: 0.009866 | Avg Time: 0.04136 | Time Left: 64.31\n",
            "Epoch: 01/02 | Batch: 00333/01887 | Loss: 0.3258 | Avg Loss: 0.4587 | Prediction: 2.606898307800293 | Label: 1 | Time: 0.004153 | Avg Time: 0.04125 | Time Left: 64.1\n",
            "Epoch: 01/02 | Batch: 00334/01887 | Loss: 0.1183 | Avg Loss: 0.4576 | Prediction: 2.280203104019165 | Label: 1 | Time: 0.008468 | Avg Time: 0.04115 | Time Left: 63.9\n",
            "Epoch: 01/02 | Batch: 00335/01887 | Loss: 0.4596 | Avg Loss: 0.4576 | Prediction: 2.295701503753662 | Label: 1 | Time: 0.008514 | Avg Time: 0.04105 | Time Left: 63.71\n",
            "Epoch: 01/02 | Batch: 00336/01887 | Loss: 0.1021 | Avg Loss: 0.4566 | Prediction: -3.069725751876831 | Label: 0 | Time: 0.0115 | Avg Time: 0.04096 | Time Left: 63.54\n",
            "Epoch: 01/02 | Batch: 00337/01887 | Loss: 0.09151 | Avg Loss: 0.4555 | Prediction: -8.034872055053711 | Label: 0 | Time: 0.008713 | Avg Time: 0.04087 | Time Left: 63.35\n",
            "Epoch: 01/02 | Batch: 00338/01887 | Loss: 0.1159 | Avg Loss: 0.4545 | Prediction: -4.349036693572998 | Label: 0 | Time: 0.004521 | Avg Time: 0.04076 | Time Left: 63.14\n",
            "Epoch: 01/02 | Batch: 00339/01887 | Loss: 0.3252 | Avg Loss: 0.4541 | Prediction: 1.419297218322754 | Label: 1 | Time: 0.007765 | Avg Time: 0.04066 | Time Left: 62.95\n",
            "Epoch: 01/02 | Batch: 00340/01887 | Loss: 0.5564 | Avg Loss: 0.4544 | Prediction: 1.5837230682373047 | Label: 1 | Time: 0.004247 | Avg Time: 0.04056 | Time Left: 62.74\n",
            "Epoch: 01/02 | Batch: 00341/01887 | Loss: 0.209 | Avg Loss: 0.4537 | Prediction: 1.9634655714035034 | Label: 1 | Time: 0.01419 | Avg Time: 0.04048 | Time Left: 62.58\n",
            "Epoch: 01/02 | Batch: 00342/01887 | Loss: 0.06259 | Avg Loss: 0.4525 | Prediction: 2.2512035369873047 | Label: 1 | Time: 0.003963 | Avg Time: 0.04037 | Time Left: 62.38\n",
            "Epoch: 01/02 | Batch: 00343/01887 | Loss: 0.07689 | Avg Loss: 0.4515 | Prediction: 2.01977276802063 | Label: 1 | Time: 0.005706 | Avg Time: 0.04027 | Time Left: 62.18\n",
            "Epoch: 01/02 | Batch: 00344/01887 | Loss: 0.4718 | Avg Loss: 0.4515 | Prediction: -8.0457181930542 | Label: 0 | Time: 0.004474 | Avg Time: 0.04017 | Time Left: 61.98\n",
            "Epoch: 01/02 | Batch: 00345/01887 | Loss: 0.3239 | Avg Loss: 0.4511 | Prediction: 3.071786403656006 | Label: 1 | Time: 0.004076 | Avg Time: 0.04006 | Time Left: 61.78\n",
            "Epoch: 01/02 | Batch: 00346/01887 | Loss: 0.05527 | Avg Loss: 0.45 | Prediction: -6.638473987579346 | Label: 0 | Time: 0.009571 | Avg Time: 0.03997 | Time Left: 61.6\n",
            "Epoch: 01/02 | Batch: 00347/01887 | Loss: 0.03496 | Avg Loss: 0.4488 | Prediction: 3.387157917022705 | Label: 1 | Time: 0.009611 | Avg Time: 0.03989 | Time Left: 61.43\n",
            "Epoch: 01/02 | Batch: 00348/01887 | Loss: 0.02241 | Avg Loss: 0.4476 | Prediction: 4.157723903656006 | Label: 1 | Time: 0.009482 | Avg Time: 0.0398 | Time Left: 61.25\n",
            "Epoch: 01/02 | Batch: 00349/01887 | Loss: 0.2894 | Avg Loss: 0.4471 | Prediction: -4.118535995483398 | Label: 0 | Time: 0.009661 | Avg Time: 0.03971 | Time Left: 61.08\n",
            "Epoch: 01/02 | Batch: 00350/01887 | Loss: 0.1113 | Avg Loss: 0.4462 | Prediction: -2.3155276775360107 | Label: 0 | Time: 0.008577 | Avg Time: 0.03962 | Time Left: 60.9\n",
            "Epoch: 01/02 | Batch: 00351/01887 | Loss: 0.03282 | Avg Loss: 0.445 | Prediction: 4.638187408447266 | Label: 1 | Time: 0.006038 | Avg Time: 0.03953 | Time Left: 60.72\n",
            "Epoch: 01/02 | Batch: 00352/01887 | Loss: 0.2016 | Avg Loss: 0.4443 | Prediction: -2.3752529621124268 | Label: 1 | Time: 0.007951 | Avg Time: 0.03944 | Time Left: 60.54\n",
            "Epoch: 01/02 | Batch: 00353/01887 | Loss: 0.3071 | Avg Loss: 0.4439 | Prediction: 4.7381744384765625 | Label: 1 | Time: 0.03041 | Avg Time: 0.03941 | Time Left: 60.46\n",
            "Epoch: 01/02 | Batch: 00354/01887 | Loss: 0.315 | Avg Loss: 0.4435 | Prediction: 4.978311538696289 | Label: 1 | Time: 0.01068 | Avg Time: 0.03933 | Time Left: 60.3\n",
            "Epoch: 01/02 | Batch: 00355/01887 | Loss: 0.2074 | Avg Loss: 0.4429 | Prediction: 4.945781707763672 | Label: 1 | Time: 0.009086 | Avg Time: 0.03925 | Time Left: 60.13\n",
            "Epoch: 01/02 | Batch: 00356/01887 | Loss: 0.01776 | Avg Loss: 0.4417 | Prediction: 4.547530651092529 | Label: 1 | Time: 0.0228 | Avg Time: 0.0392 | Time Left: 60.02\n",
            "Epoch: 01/02 | Batch: 00357/01887 | Loss: 0.03281 | Avg Loss: 0.4405 | Prediction: 4.295820713043213 | Label: 1 | Time: 0.01284 | Avg Time: 0.03913 | Time Left: 59.86\n",
            "Epoch: 01/02 | Batch: 00358/01887 | Loss: 0.02269 | Avg Loss: 0.4394 | Prediction: 4.715138912200928 | Label: 1 | Time: 0.006658 | Avg Time: 0.03904 | Time Left: 59.69\n",
            "Epoch: 01/02 | Batch: 00359/01887 | Loss: 0.1855 | Avg Loss: 0.4387 | Prediction: -1.8593549728393555 | Label: 0 | Time: 0.01312 | Avg Time: 0.03896 | Time Left: 59.54\n",
            "Epoch: 01/02 | Batch: 00360/01887 | Loss: 0.06986 | Avg Loss: 0.4376 | Prediction: -6.063734531402588 | Label: 0 | Time: 0.008574 | Avg Time: 0.03888 | Time Left: 59.37\n",
            "Epoch: 01/02 | Batch: 00361/01887 | Loss: 0.02446 | Avg Loss: 0.4365 | Prediction: 4.275874614715576 | Label: 1 | Time: 0.006202 | Avg Time: 0.03879 | Time Left: 59.19\n",
            "Epoch: 01/02 | Batch: 00362/01887 | Loss: 0.2075 | Avg Loss: 0.4359 | Prediction: 4.019100666046143 | Label: 1 | Time: 0.007158 | Avg Time: 0.0387 | Time Left: 59.02\n",
            "Epoch: 01/02 | Batch: 00363/01887 | Loss: 0.08365 | Avg Loss: 0.4349 | Prediction: -3.3034908771514893 | Label: 0 | Time: 0.008663 | Avg Time: 0.03862 | Time Left: 58.86\n",
            "Epoch: 01/02 | Batch: 00364/01887 | Loss: 0.335 | Avg Loss: 0.4346 | Prediction: -3.5609397888183594 | Label: 0 | Time: 0.01484 | Avg Time: 0.03855 | Time Left: 58.72\n",
            "Epoch: 01/02 | Batch: 00365/01887 | Loss: 0.2301 | Avg Loss: 0.4341 | Prediction: -3.2947170734405518 | Label: 0 | Time: 0.007799 | Avg Time: 0.03847 | Time Left: 58.55\n",
            "Epoch: 01/02 | Batch: 00366/01887 | Loss: 0.1597 | Avg Loss: 0.4333 | Prediction: -2.409090518951416 | Label: 0 | Time: 0.008586 | Avg Time: 0.03839 | Time Left: 58.39\n",
            "Epoch: 01/02 | Batch: 00367/01887 | Loss: 0.226 | Avg Loss: 0.4327 | Prediction: -5.0353803634643555 | Label: 0 | Time: 0.01013 | Avg Time: 0.03831 | Time Left: 58.23\n",
            "Epoch: 01/02 | Batch: 00368/01887 | Loss: 0.06128 | Avg Loss: 0.4317 | Prediction: 2.868675708770752 | Label: 1 | Time: 0.02251 | Avg Time: 0.03827 | Time Left: 58.13\n",
            "Epoch: 01/02 | Batch: 00369/01887 | Loss: 0.2528 | Avg Loss: 0.4312 | Prediction: 2.9229180812835693 | Label: 1 | Time: 0.007049 | Avg Time: 0.03818 | Time Left: 57.96\n",
            "Epoch: 01/02 | Batch: 00370/01887 | Loss: 0.0653 | Avg Loss: 0.4303 | Prediction: 2.3778975009918213 | Label: 1 | Time: 0.009389 | Avg Time: 0.03811 | Time Left: 57.81\n",
            "Epoch: 01/02 | Batch: 00371/01887 | Loss: 0.05873 | Avg Loss: 0.4293 | Prediction: -5.064705848693848 | Label: 0 | Time: 0.007026 | Avg Time: 0.03802 | Time Left: 57.64\n",
            "Epoch: 01/02 | Batch: 00372/01887 | Loss: 0.5097 | Avg Loss: 0.4295 | Prediction: 2.359675884246826 | Label: 1 | Time: 0.009507 | Avg Time: 0.03794 | Time Left: 57.49\n",
            "Epoch: 01/02 | Batch: 00373/01887 | Loss: 0.07209 | Avg Loss: 0.4285 | Prediction: 2.068150520324707 | Label: 1 | Time: 0.008552 | Avg Time: 0.03787 | Time Left: 57.33\n",
            "Epoch: 01/02 | Batch: 00374/01887 | Loss: 0.2587 | Avg Loss: 0.4281 | Prediction: -4.722629070281982 | Label: 0 | Time: 0.009495 | Avg Time: 0.03779 | Time Left: 57.18\n",
            "Epoch: 01/02 | Batch: 00375/01887 | Loss: 0.1945 | Avg Loss: 0.4274 | Prediction: -5.130258083343506 | Label: 0 | Time: 0.01176 | Avg Time: 0.03772 | Time Left: 57.03\n",
            "Epoch: 01/02 | Batch: 00376/01887 | Loss: 0.08446 | Avg Loss: 0.4265 | Prediction: 1.8826370239257812 | Label: 1 | Time: 0.01238 | Avg Time: 0.03765 | Time Left: 56.89\n",
            "Epoch: 01/02 | Batch: 00377/01887 | Loss: 0.06107 | Avg Loss: 0.4256 | Prediction: 2.493286371231079 | Label: 1 | Time: 0.004787 | Avg Time: 0.03757 | Time Left: 56.72\n",
            "Epoch: 01/02 | Batch: 00378/01887 | Loss: 0.07093 | Avg Loss: 0.4246 | Prediction: 2.500189781188965 | Label: 1 | Time: 0.01537 | Avg Time: 0.03751 | Time Left: 56.6\n",
            "Epoch: 01/02 | Batch: 00379/01887 | Loss: 0.06185 | Avg Loss: 0.4237 | Prediction: 2.236685276031494 | Label: 1 | Time: 0.006719 | Avg Time: 0.03743 | Time Left: 56.44\n",
            "Epoch: 01/02 | Batch: 00380/01887 | Loss: 0.03717 | Avg Loss: 0.4226 | Prediction: -4.505758285522461 | Label: 0 | Time: 0.00944 | Avg Time: 0.03735 | Time Left: 56.29\n",
            "Epoch: 01/02 | Batch: 00381/01887 | Loss: 0.1328 | Avg Loss: 0.4219 | Prediction: -3.298785448074341 | Label: 0 | Time: 0.01272 | Avg Time: 0.03729 | Time Left: 56.16\n",
            "Epoch: 01/02 | Batch: 00382/01887 | Loss: 0.02027 | Avg Loss: 0.4208 | Prediction: 3.7793736457824707 | Label: 1 | Time: 0.007846 | Avg Time: 0.03721 | Time Left: 56.0\n",
            "Epoch: 01/02 | Batch: 00383/01887 | Loss: 0.01814 | Avg Loss: 0.4198 | Prediction: 3.6661078929901123 | Label: 1 | Time: 0.007073 | Avg Time: 0.03713 | Time Left: 55.85\n",
            "Epoch: 01/02 | Batch: 00384/01887 | Loss: 0.05399 | Avg Loss: 0.4188 | Prediction: 4.102208137512207 | Label: 1 | Time: 0.005652 | Avg Time: 0.03705 | Time Left: 55.69\n",
            "Epoch: 01/02 | Batch: 00385/01887 | Loss: 0.342 | Avg Loss: 0.4186 | Prediction: 3.9774158000946045 | Label: 1 | Time: 0.005243 | Avg Time: 0.03697 | Time Left: 55.53\n",
            "Epoch: 01/02 | Batch: 00386/01887 | Loss: 0.1848 | Avg Loss: 0.418 | Prediction: 4.6128926277160645 | Label: 1 | Time: 0.01373 | Avg Time: 0.03691 | Time Left: 55.4\n",
            "Epoch: 01/02 | Batch: 00387/01887 | Loss: 0.2986 | Avg Loss: 0.4177 | Prediction: 4.361237525939941 | Label: 1 | Time: 0.009663 | Avg Time: 0.03684 | Time Left: 55.26\n",
            "Epoch: 01/02 | Batch: 00388/01887 | Loss: 0.4993 | Avg Loss: 0.4179 | Prediction: -6.24530029296875 | Label: 0 | Time: 0.004186 | Avg Time: 0.03675 | Time Left: 55.09\n",
            "Epoch: 01/02 | Batch: 00389/01887 | Loss: 0.1633 | Avg Loss: 0.4173 | Prediction: 4.196017742156982 | Label: 1 | Time: 0.0111 | Avg Time: 0.03669 | Time Left: 54.96\n",
            "Epoch: 01/02 | Batch: 00390/01887 | Loss: 0.3571 | Avg Loss: 0.4171 | Prediction: 4.14180326461792 | Label: 1 | Time: 0.01275 | Avg Time: 0.03663 | Time Left: 54.83\n",
            "Epoch: 01/02 | Batch: 00391/01887 | Loss: 0.1631 | Avg Loss: 0.4165 | Prediction: -1.984163522720337 | Label: 1 | Time: 0.008468 | Avg Time: 0.03655 | Time Left: 54.68\n",
            "Epoch: 01/02 | Batch: 00392/01887 | Loss: 0.01699 | Avg Loss: 0.4154 | Prediction: 3.6984901428222656 | Label: 1 | Time: 0.005356 | Avg Time: 0.03647 | Time Left: 54.53\n",
            "Epoch: 01/02 | Batch: 00393/01887 | Loss: 0.01901 | Avg Loss: 0.4144 | Prediction: 3.6450858116149902 | Label: 1 | Time: 0.01036 | Avg Time: 0.03641 | Time Left: 54.39\n",
            "Epoch: 01/02 | Batch: 00394/01887 | Loss: 0.02678 | Avg Loss: 0.4135 | Prediction: 3.6402084827423096 | Label: 1 | Time: 0.00782 | Avg Time: 0.03633 | Time Left: 54.25\n",
            "Epoch: 01/02 | Batch: 00395/01887 | Loss: 0.02373 | Avg Loss: 0.4125 | Prediction: -2.958526134490967 | Label: 0 | Time: 0.01309 | Avg Time: 0.03628 | Time Left: 54.12\n",
            "Epoch: 01/02 | Batch: 00396/01887 | Loss: 0.02637 | Avg Loss: 0.4115 | Prediction: -5.599158763885498 | Label: 0 | Time: 0.02015 | Avg Time: 0.03624 | Time Left: 54.03\n",
            "Epoch: 01/02 | Batch: 00397/01887 | Loss: 0.02594 | Avg Loss: 0.4105 | Prediction: -2.9608535766601562 | Label: 0 | Time: 0.01013 | Avg Time: 0.03617 | Time Left: 53.89\n",
            "Epoch: 01/02 | Batch: 00398/01887 | Loss: 0.02084 | Avg Loss: 0.4095 | Prediction: -3.0058281421661377 | Label: 0 | Time: 0.005147 | Avg Time: 0.03609 | Time Left: 53.74\n",
            "Epoch: 01/02 | Batch: 00399/01887 | Loss: 0.02514 | Avg Loss: 0.4086 | Prediction: -4.328028202056885 | Label: 0 | Time: 0.00825 | Avg Time: 0.03602 | Time Left: 53.6\n",
            "Epoch: 01/02 | Batch: 00400/01887 | Loss: 0.1357 | Avg Loss: 0.4079 | Prediction: -0.4470934271812439 | Label: 0 | Time: 0.008243 | Avg Time: 0.03595 | Time Left: 53.46\n",
            "Epoch: 01/02 | Batch: 00401/01887 | Loss: 0.3107 | Avg Loss: 0.4077 | Prediction: -2.5202202796936035 | Label: 1 | Time: 0.007109 | Avg Time: 0.03588 | Time Left: 53.32\n",
            "Epoch: 01/02 | Batch: 00402/01887 | Loss: 0.02235 | Avg Loss: 0.4067 | Prediction: -2.8713417053222656 | Label: 0 | Time: 0.004177 | Avg Time: 0.0358 | Time Left: 53.17\n",
            "Epoch: 01/02 | Batch: 00403/01887 | Loss: 0.1987 | Avg Loss: 0.4062 | Prediction: 3.9631919860839844 | Label: 1 | Time: 0.01769 | Avg Time: 0.03576 | Time Left: 53.06\n",
            "Epoch: 01/02 | Batch: 00404/01887 | Loss: 0.02722 | Avg Loss: 0.4052 | Prediction: -5.050899028778076 | Label: 0 | Time: 0.02062 | Avg Time: 0.03572 | Time Left: 52.97\n",
            "Epoch: 01/02 | Batch: 00405/01887 | Loss: 0.03926 | Avg Loss: 0.4043 | Prediction: 3.1025993824005127 | Label: 1 | Time: 0.01726 | Avg Time: 0.03567 | Time Left: 52.87\n",
            "Epoch: 01/02 | Batch: 00406/01887 | Loss: 0.197 | Avg Loss: 0.4038 | Prediction: 3.2067081928253174 | Label: 1 | Time: 0.01285 | Avg Time: 0.03562 | Time Left: 52.75\n",
            "Epoch: 01/02 | Batch: 00407/01887 | Loss: 0.5306 | Avg Loss: 0.4041 | Prediction: 3.369001626968384 | Label: 1 | Time: 0.004648 | Avg Time: 0.03554 | Time Left: 52.6\n",
            "Epoch: 01/02 | Batch: 00408/01887 | Loss: 0.2019 | Avg Loss: 0.4036 | Prediction: -3.954240560531616 | Label: 0 | Time: 0.01571 | Avg Time: 0.03549 | Time Left: 52.49\n",
            "Epoch: 01/02 | Batch: 00409/01887 | Loss: 0.04369 | Avg Loss: 0.4028 | Prediction: 2.5228450298309326 | Label: 1 | Time: 0.01672 | Avg Time: 0.03545 | Time Left: 52.39\n",
            "Epoch: 01/02 | Batch: 00410/01887 | Loss: 0.08617 | Avg Loss: 0.402 | Prediction: -6.591581344604492 | Label: 0 | Time: 0.00803 | Avg Time: 0.03538 | Time Left: 52.26\n",
            "Epoch: 01/02 | Batch: 00411/01887 | Loss: 0.08566 | Avg Loss: 0.4012 | Prediction: 2.0436055660247803 | Label: 1 | Time: 0.01262 | Avg Time: 0.03532 | Time Left: 52.14\n",
            "Epoch: 01/02 | Batch: 00412/01887 | Loss: 0.05817 | Avg Loss: 0.4004 | Prediction: -7.301766395568848 | Label: 0 | Time: 0.01689 | Avg Time: 0.03528 | Time Left: 52.04\n",
            "Epoch: 01/02 | Batch: 00413/01887 | Loss: 0.08725 | Avg Loss: 0.3996 | Prediction: 2.1683666706085205 | Label: 1 | Time: 0.005919 | Avg Time: 0.03521 | Time Left: 51.9\n",
            "Epoch: 01/02 | Batch: 00414/01887 | Loss: 0.04852 | Avg Loss: 0.3988 | Prediction: -7.3408894538879395 | Label: 0 | Time: 0.008573 | Avg Time: 0.03514 | Time Left: 51.77\n",
            "Epoch: 01/02 | Batch: 00415/01887 | Loss: 0.2193 | Avg Loss: 0.3984 | Prediction: -6.780611038208008 | Label: 0 | Time: 0.01119 | Avg Time: 0.03509 | Time Left: 51.65\n",
            "Epoch: 01/02 | Batch: 00416/01887 | Loss: 0.2443 | Avg Loss: 0.398 | Prediction: 3.1233434677124023 | Label: 1 | Time: 0.005718 | Avg Time: 0.03502 | Time Left: 51.51\n",
            "Epoch: 01/02 | Batch: 00417/01887 | Loss: 0.1733 | Avg Loss: 0.3974 | Prediction: -7.010889530181885 | Label: 0 | Time: 0.0127 | Avg Time: 0.03496 | Time Left: 51.39\n",
            "Epoch: 01/02 | Batch: 00418/01887 | Loss: 0.08066 | Avg Loss: 0.3967 | Prediction: 3.22420597076416 | Label: 1 | Time: 0.02018 | Avg Time: 0.03493 | Time Left: 51.31\n",
            "Epoch: 01/02 | Batch: 00419/01887 | Loss: 0.03734 | Avg Loss: 0.3958 | Prediction: 2.961796998977661 | Label: 1 | Time: 0.006501 | Avg Time: 0.03486 | Time Left: 51.17\n",
            "Epoch: 01/02 | Batch: 00420/01887 | Loss: 0.3126 | Avg Loss: 0.3956 | Prediction: 3.2999069690704346 | Label: 1 | Time: 0.01757 | Avg Time: 0.03482 | Time Left: 51.08\n",
            "Epoch: 01/02 | Batch: 00421/01887 | Loss: 0.4038 | Avg Loss: 0.3956 | Prediction: 2.841918468475342 | Label: 1 | Time: 0.01739 | Avg Time: 0.03478 | Time Left: 50.98\n",
            "Epoch: 01/02 | Batch: 00422/01887 | Loss: 0.04988 | Avg Loss: 0.3948 | Prediction: -8.237862586975098 | Label: 0 | Time: 0.007689 | Avg Time: 0.03471 | Time Left: 50.85\n",
            "Epoch: 01/02 | Batch: 00423/01887 | Loss: 0.04388 | Avg Loss: 0.394 | Prediction: -5.807960033416748 | Label: 0 | Time: 0.009665 | Avg Time: 0.03465 | Time Left: 50.73\n",
            "Epoch: 01/02 | Batch: 00424/01887 | Loss: 0.04545 | Avg Loss: 0.3932 | Prediction: 2.5432660579681396 | Label: 1 | Time: 0.01394 | Avg Time: 0.0346 | Time Left: 50.63\n",
            "Epoch: 01/02 | Batch: 00425/01887 | Loss: 0.0392 | Avg Loss: 0.3923 | Prediction: -8.465781211853027 | Label: 0 | Time: 0.005691 | Avg Time: 0.03454 | Time Left: 50.49\n",
            "Epoch: 01/02 | Batch: 00426/01887 | Loss: 0.0386 | Avg Loss: 0.3915 | Prediction: 2.8814594745635986 | Label: 1 | Time: 0.01114 | Avg Time: 0.03448 | Time Left: 50.38\n",
            "Epoch: 01/02 | Batch: 00427/01887 | Loss: 0.01818 | Avg Loss: 0.3906 | Prediction: -5.682771682739258 | Label: 0 | Time: 0.006492 | Avg Time: 0.03442 | Time Left: 50.25\n",
            "Epoch: 01/02 | Batch: 00428/01887 | Loss: 0.02791 | Avg Loss: 0.3898 | Prediction: -1.8066848516464233 | Label: 0 | Time: 0.009581 | Avg Time: 0.03436 | Time Left: 50.13\n",
            "Epoch: 01/02 | Batch: 00429/01887 | Loss: 0.4926 | Avg Loss: 0.39 | Prediction: 4.114227771759033 | Label: 1 | Time: 0.01464 | Avg Time: 0.03431 | Time Left: 50.03\n",
            "Epoch: 01/02 | Batch: 00430/01887 | Loss: 0.0404 | Avg Loss: 0.3892 | Prediction: 4.226812362670898 | Label: 1 | Time: 0.01458 | Avg Time: 0.03427 | Time Left: 49.93\n",
            "Epoch: 01/02 | Batch: 00431/01887 | Loss: 0.03145 | Avg Loss: 0.3884 | Prediction: -1.5819296836853027 | Label: 0 | Time: 0.009802 | Avg Time: 0.03421 | Time Left: 49.81\n",
            "Epoch: 01/02 | Batch: 00432/01887 | Loss: 0.03324 | Avg Loss: 0.3876 | Prediction: 3.842616558074951 | Label: 1 | Time: 0.004862 | Avg Time: 0.03414 | Time Left: 49.68\n",
            "Epoch: 01/02 | Batch: 00433/01887 | Loss: 0.01721 | Avg Loss: 0.3867 | Prediction: 3.774932861328125 | Label: 1 | Time: 0.004107 | Avg Time: 0.03407 | Time Left: 49.54\n",
            "Epoch: 01/02 | Batch: 00434/01887 | Loss: 0.0138 | Avg Loss: 0.3859 | Prediction: 4.155911922454834 | Label: 1 | Time: 0.01677 | Avg Time: 0.03403 | Time Left: 49.45\n",
            "Epoch: 01/02 | Batch: 00435/01887 | Loss: 0.07998 | Avg Loss: 0.3851 | Prediction: 4.025937557220459 | Label: 1 | Time: 0.004516 | Avg Time: 0.03396 | Time Left: 49.32\n",
            "Epoch: 01/02 | Batch: 00436/01887 | Loss: 0.514 | Avg Loss: 0.3854 | Prediction: 3.6797308921813965 | Label: 1 | Time: 0.01384 | Avg Time: 0.03392 | Time Left: 49.22\n",
            "Epoch: 01/02 | Batch: 00437/01887 | Loss: 0.0154 | Avg Loss: 0.3846 | Prediction: 4.04612398147583 | Label: 1 | Time: 0.02527 | Avg Time: 0.0339 | Time Left: 49.15\n",
            "Epoch: 01/02 | Batch: 00438/01887 | Loss: 0.0459 | Avg Loss: 0.3838 | Prediction: 3.762669324874878 | Label: 1 | Time: 0.0134 | Avg Time: 0.03385 | Time Left: 49.05\n",
            "Epoch: 01/02 | Batch: 00439/01887 | Loss: 0.02027 | Avg Loss: 0.383 | Prediction: -8.186951637268066 | Label: 0 | Time: 0.01329 | Avg Time: 0.0338 | Time Left: 48.95\n",
            "Epoch: 01/02 | Batch: 00440/01887 | Loss: 0.01297 | Avg Loss: 0.3822 | Prediction: -5.354298114776611 | Label: 0 | Time: 0.005841 | Avg Time: 0.03374 | Time Left: 48.82\n",
            "Epoch: 01/02 | Batch: 00441/01887 | Loss: 0.1872 | Avg Loss: 0.3817 | Prediction: 4.116576671600342 | Label: 1 | Time: 0.006002 | Avg Time: 0.03368 | Time Left: 48.7\n",
            "Epoch: 01/02 | Batch: 00442/01887 | Loss: 0.3922 | Avg Loss: 0.3817 | Prediction: -2.8560073375701904 | Label: 0 | Time: 0.02279 | Avg Time: 0.03365 | Time Left: 48.63\n",
            "Epoch: 01/02 | Batch: 00443/01887 | Loss: 0.02484 | Avg Loss: 0.3809 | Prediction: 3.0205447673797607 | Label: 1 | Time: 0.008502 | Avg Time: 0.0336 | Time Left: 48.51\n",
            "Epoch: 01/02 | Batch: 00444/01887 | Loss: 0.03507 | Avg Loss: 0.3802 | Prediction: 3.336714267730713 | Label: 1 | Time: 0.01541 | Avg Time: 0.03356 | Time Left: 48.42\n",
            "Epoch: 01/02 | Batch: 00445/01887 | Loss: 0.04151 | Avg Loss: 0.3794 | Prediction: 2.940764904022217 | Label: 1 | Time: 0.02069 | Avg Time: 0.03353 | Time Left: 48.35\n",
            "Epoch: 01/02 | Batch: 00446/01887 | Loss: 0.02792 | Avg Loss: 0.3786 | Prediction: -9.07166576385498 | Label: 0 | Time: 0.006109 | Avg Time: 0.03347 | Time Left: 48.22\n",
            "Epoch: 01/02 | Batch: 00447/01887 | Loss: 0.05463 | Avg Loss: 0.3779 | Prediction: 2.792290210723877 | Label: 1 | Time: 0.01602 | Avg Time: 0.03343 | Time Left: 48.13\n",
            "Epoch: 01/02 | Batch: 00448/01887 | Loss: 0.04682 | Avg Loss: 0.3771 | Prediction: 2.630575656890869 | Label: 1 | Time: 0.01622 | Avg Time: 0.03339 | Time Left: 48.05\n",
            "Epoch: 01/02 | Batch: 00449/01887 | Loss: 0.04018 | Avg Loss: 0.3764 | Prediction: -3.2667980194091797 | Label: 0 | Time: 0.009406 | Avg Time: 0.03333 | Time Left: 47.94\n",
            "Epoch: 01/02 | Batch: 00450/01887 | Loss: 0.03002 | Avg Loss: 0.3756 | Prediction: 2.9612033367156982 | Label: 1 | Time: 0.004415 | Avg Time: 0.03327 | Time Left: 47.81\n",
            "Epoch: 01/02 | Batch: 00451/01887 | Loss: 0.367 | Avg Loss: 0.3756 | Prediction: 3.071988821029663 | Label: 1 | Time: 0.005236 | Avg Time: 0.03321 | Time Left: 47.69\n",
            "Epoch: 01/02 | Batch: 00452/01887 | Loss: 0.01263 | Avg Loss: 0.3748 | Prediction: 4.161313533782959 | Label: 1 | Time: 0.01678 | Avg Time: 0.03317 | Time Left: 47.6\n",
            "Epoch: 01/02 | Batch: 00453/01887 | Loss: 0.005662 | Avg Loss: 0.374 | Prediction: -6.846254348754883 | Label: 0 | Time: 0.005959 | Avg Time: 0.03311 | Time Left: 47.48\n",
            "Epoch: 01/02 | Batch: 00454/01887 | Loss: 0.003966 | Avg Loss: 0.3732 | Prediction: 5.298774719238281 | Label: 1 | Time: 0.004869 | Avg Time: 0.03305 | Time Left: 47.36\n",
            "Epoch: 01/02 | Batch: 00455/01887 | Loss: 0.2093 | Avg Loss: 0.3728 | Prediction: 0.910720705986023 | Label: 0 | Time: 0.01653 | Avg Time: 0.03301 | Time Left: 47.28\n",
            "Epoch: 01/02 | Batch: 00456/01887 | Loss: 0.03462 | Avg Loss: 0.3721 | Prediction: -3.027832269668579 | Label: 0 | Time: 0.01396 | Avg Time: 0.03297 | Time Left: 47.18\n",
            "Epoch: 01/02 | Batch: 00457/01887 | Loss: 0.003716 | Avg Loss: 0.3713 | Prediction: 5.79541540145874 | Label: 1 | Time: 0.01672 | Avg Time: 0.03294 | Time Left: 47.1\n",
            "Epoch: 01/02 | Batch: 00458/01887 | Loss: 0.1095 | Avg Loss: 0.3707 | Prediction: -7.867751598358154 | Label: 0 | Time: 0.01472 | Avg Time: 0.0329 | Time Left: 47.01\n",
            "Epoch: 01/02 | Batch: 00459/01887 | Loss: 0.03601 | Avg Loss: 0.37 | Prediction: 5.48939847946167 | Label: 1 | Time: 0.01685 | Avg Time: 0.03286 | Time Left: 46.93\n",
            "Epoch: 01/02 | Batch: 00460/01887 | Loss: 0.004725 | Avg Loss: 0.3692 | Prediction: 5.1108012199401855 | Label: 1 | Time: 0.007495 | Avg Time: 0.03281 | Time Left: 46.81\n",
            "Epoch: 01/02 | Batch: 00461/01887 | Loss: 0.2005 | Avg Loss: 0.3688 | Prediction: -3.9056220054626465 | Label: 0 | Time: 0.01936 | Avg Time: 0.03278 | Time Left: 46.74\n",
            "Epoch: 01/02 | Batch: 00462/01887 | Loss: 0.02113 | Avg Loss: 0.368 | Prediction: -8.555269241333008 | Label: 0 | Time: 0.005345 | Avg Time: 0.03272 | Time Left: 46.62\n",
            "Epoch: 01/02 | Batch: 00463/01887 | Loss: 0.008931 | Avg Loss: 0.3673 | Prediction: -4.579387187957764 | Label: 0 | Time: 0.007315 | Avg Time: 0.03266 | Time Left: 46.51\n",
            "Epoch: 01/02 | Batch: 00464/01887 | Loss: 0.01424 | Avg Loss: 0.3665 | Prediction: -10.968050956726074 | Label: 0 | Time: 0.01232 | Avg Time: 0.03262 | Time Left: 46.42\n",
            "Epoch: 01/02 | Batch: 00465/01887 | Loss: 0.3219 | Avg Loss: 0.3664 | Prediction: 3.161702871322632 | Label: 1 | Time: 0.00721 | Avg Time: 0.03256 | Time Left: 46.31\n",
            "Epoch: 01/02 | Batch: 00466/01887 | Loss: 0.1407 | Avg Loss: 0.3659 | Prediction: -5.279666900634766 | Label: 0 | Time: 0.01061 | Avg Time: 0.03252 | Time Left: 46.21\n",
            "Epoch: 01/02 | Batch: 00467/01887 | Loss: 0.0268 | Avg Loss: 0.3652 | Prediction: 2.6625864505767822 | Label: 1 | Time: 0.009984 | Avg Time: 0.03247 | Time Left: 46.11\n",
            "Epoch: 01/02 | Batch: 00468/01887 | Loss: 0.04082 | Avg Loss: 0.3645 | Prediction: 3.075648546218872 | Label: 1 | Time: 0.01506 | Avg Time: 0.03243 | Time Left: 46.02\n",
            "Epoch: 01/02 | Batch: 00469/01887 | Loss: 0.0363 | Avg Loss: 0.3638 | Prediction: -10.380790710449219 | Label: 0 | Time: 0.01663 | Avg Time: 0.0324 | Time Left: 45.94\n",
            "Epoch: 01/02 | Batch: 00470/01887 | Loss: 0.2046 | Avg Loss: 0.3635 | Prediction: 3.6416497230529785 | Label: 1 | Time: 0.01833 | Avg Time: 0.03237 | Time Left: 45.87\n",
            "Epoch: 01/02 | Batch: 00471/01887 | Loss: 0.03088 | Avg Loss: 0.3628 | Prediction: 3.0814082622528076 | Label: 1 | Time: 0.01271 | Avg Time: 0.03233 | Time Left: 45.77\n",
            "Epoch: 01/02 | Batch: 00472/01887 | Loss: 0.03382 | Avg Loss: 0.3621 | Prediction: 2.943140983581543 | Label: 1 | Time: 0.01383 | Avg Time: 0.03229 | Time Left: 45.69\n",
            "Epoch: 01/02 | Batch: 00473/01887 | Loss: 0.02276 | Avg Loss: 0.3613 | Prediction: 3.8585522174835205 | Label: 1 | Time: 0.024 | Avg Time: 0.03227 | Time Left: 45.63\n",
            "Epoch: 01/02 | Batch: 00474/01887 | Loss: 0.01196 | Avg Loss: 0.3606 | Prediction: 4.134279251098633 | Label: 1 | Time: 0.02312 | Avg Time: 0.03225 | Time Left: 45.57\n",
            "Epoch: 01/02 | Batch: 00475/01887 | Loss: 0.01111 | Avg Loss: 0.3599 | Prediction: -7.987033843994141 | Label: 0 | Time: 0.004815 | Avg Time: 0.03219 | Time Left: 45.46\n",
            "Epoch: 01/02 | Batch: 00476/01887 | Loss: 0.01339 | Avg Loss: 0.3591 | Prediction: -2.130049228668213 | Label: 0 | Time: 0.006798 | Avg Time: 0.03214 | Time Left: 45.35\n",
            "Epoch: 01/02 | Batch: 00477/01887 | Loss: 0.468 | Avg Loss: 0.3594 | Prediction: -6.736262798309326 | Label: 0 | Time: 0.01352 | Avg Time: 0.0321 | Time Left: 45.26\n",
            "Epoch: 01/02 | Batch: 00478/01887 | Loss: 0.006576 | Avg Loss: 0.3586 | Prediction: -10.406078338623047 | Label: 0 | Time: 0.02115 | Avg Time: 0.03208 | Time Left: 45.2\n",
            "Epoch: 01/02 | Batch: 00479/01887 | Loss: 0.006451 | Avg Loss: 0.3579 | Prediction: 4.414949893951416 | Label: 1 | Time: 0.01167 | Avg Time: 0.03203 | Time Left: 45.1\n",
            "Epoch: 01/02 | Batch: 00480/01887 | Loss: 0.01134 | Avg Loss: 0.3572 | Prediction: 4.448054313659668 | Label: 1 | Time: 0.005275 | Avg Time: 0.03198 | Time Left: 44.99\n",
            "Epoch: 01/02 | Batch: 00481/01887 | Loss: 0.2931 | Avg Loss: 0.357 | Prediction: 3.6988306045532227 | Label: 1 | Time: 0.01979 | Avg Time: 0.03195 | Time Left: 44.93\n",
            "Epoch: 01/02 | Batch: 00482/01887 | Loss: 0.02559 | Avg Loss: 0.3564 | Prediction: 3.318455934524536 | Label: 1 | Time: 0.008894 | Avg Time: 0.03191 | Time Left: 44.83\n",
            "Epoch: 01/02 | Batch: 00483/01887 | Loss: 0.6068 | Avg Loss: 0.3569 | Prediction: -7.10272216796875 | Label: 0 | Time: 0.007239 | Avg Time: 0.03185 | Time Left: 44.72\n",
            "Epoch: 01/02 | Batch: 00484/01887 | Loss: 0.08365 | Avg Loss: 0.3563 | Prediction: -10.625682830810547 | Label: 0 | Time: 0.006247 | Avg Time: 0.0318 | Time Left: 44.62\n",
            "Epoch: 01/02 | Batch: 00485/01887 | Loss: 1.012 | Avg Loss: 0.3577 | Prediction: -7.053102016448975 | Label: 1 | Time: 0.004376 | Avg Time: 0.03175 | Time Left: 44.51\n",
            "Epoch: 01/02 | Batch: 00486/01887 | Loss: 0.02047 | Avg Loss: 0.357 | Prediction: 3.2108561992645264 | Label: 1 | Time: 0.02234 | Avg Time: 0.03173 | Time Left: 44.45\n",
            "Epoch: 01/02 | Batch: 00487/01887 | Loss: 0.2986 | Avg Loss: 0.3569 | Prediction: 4.027845859527588 | Label: 1 | Time: 0.006249 | Avg Time: 0.03167 | Time Left: 44.34\n",
            "Epoch: 01/02 | Batch: 00488/01887 | Loss: 0.02751 | Avg Loss: 0.3562 | Prediction: -4.850991249084473 | Label: 0 | Time: 0.005976 | Avg Time: 0.03162 | Time Left: 44.24\n",
            "Epoch: 01/02 | Batch: 00489/01887 | Loss: 0.06213 | Avg Loss: 0.3556 | Prediction: 0.1321774423122406 | Label: 0 | Time: 0.02606 | Avg Time: 0.03161 | Time Left: 44.19\n",
            "Epoch: 01/02 | Batch: 00490/01887 | Loss: 0.02267 | Avg Loss: 0.3549 | Prediction: -2.0933127403259277 | Label: 0 | Time: 0.01744 | Avg Time: 0.03158 | Time Left: 44.12\n",
            "Epoch: 01/02 | Batch: 00491/01887 | Loss: 0.2182 | Avg Loss: 0.3546 | Prediction: 5.23088264465332 | Label: 1 | Time: 0.005867 | Avg Time: 0.03153 | Time Left: 44.01\n",
            "Epoch: 01/02 | Batch: 00492/01887 | Loss: 0.008554 | Avg Loss: 0.3539 | Prediction: -7.347267150878906 | Label: 0 | Time: 0.006604 | Avg Time: 0.03148 | Time Left: 43.91\n",
            "Epoch: 01/02 | Batch: 00493/01887 | Loss: 0.01551 | Avg Loss: 0.3532 | Prediction: -2.3420846462249756 | Label: 0 | Time: 0.02036 | Avg Time: 0.03146 | Time Left: 43.85\n",
            "Epoch: 01/02 | Batch: 00494/01887 | Loss: 0.0982 | Avg Loss: 0.3527 | Prediction: -3.1664159297943115 | Label: 0 | Time: 0.01719 | Avg Time: 0.03143 | Time Left: 43.78\n",
            "Epoch: 01/02 | Batch: 00495/01887 | Loss: 0.0382 | Avg Loss: 0.3521 | Prediction: -1.4839372634887695 | Label: 0 | Time: 0.004856 | Avg Time: 0.03137 | Time Left: 43.67\n",
            "Epoch: 01/02 | Batch: 00496/01887 | Loss: 0.02037 | Avg Loss: 0.3514 | Prediction: -2.492408514022827 | Label: 0 | Time: 0.008222 | Avg Time: 0.03133 | Time Left: 43.57\n",
            "Epoch: 01/02 | Batch: 00497/01887 | Loss: 0.0832 | Avg Loss: 0.3509 | Prediction: -2.374309778213501 | Label: 0 | Time: 0.01345 | Avg Time: 0.03129 | Time Left: 43.49\n",
            "Epoch: 01/02 | Batch: 00498/01887 | Loss: 0.139 | Avg Loss: 0.3504 | Prediction: 4.56186580657959 | Label: 1 | Time: 0.01379 | Avg Time: 0.03125 | Time Left: 43.41\n",
            "Epoch: 01/02 | Batch: 00499/01887 | Loss: 0.01573 | Avg Loss: 0.3498 | Prediction: 4.291619777679443 | Label: 1 | Time: 0.005404 | Avg Time: 0.0312 | Time Left: 43.31\n",
            "Epoch: 01/02 | Batch: 00500/01887 | Loss: 0.02617 | Avg Loss: 0.3491 | Prediction: -5.24009895324707 | Label: 0 | Time: 0.006612 | Avg Time: 0.03115 | Time Left: 43.21\n",
            "Epoch: 01/02 | Batch: 00501/01887 | Loss: 0.03693 | Avg Loss: 0.3485 | Prediction: 3.771768569946289 | Label: 1 | Time: 0.01659 | Avg Time: 0.03112 | Time Left: 43.14\n",
            "Epoch: 01/02 | Batch: 00502/01887 | Loss: 0.1228 | Avg Loss: 0.3481 | Prediction: 3.7470781803131104 | Label: 1 | Time: 0.01955 | Avg Time: 0.0311 | Time Left: 43.08\n",
            "Epoch: 01/02 | Batch: 00503/01887 | Loss: 0.3412 | Avg Loss: 0.348 | Prediction: 2.8288755416870117 | Label: 1 | Time: 0.01287 | Avg Time: 0.03107 | Time Left: 42.99\n",
            "Epoch: 01/02 | Batch: 00504/01887 | Loss: 0.2805 | Avg Loss: 0.3479 | Prediction: -1.3146659135818481 | Label: 0 | Time: 0.01363 | Avg Time: 0.03103 | Time Left: 42.92\n",
            "Epoch: 01/02 | Batch: 00505/01887 | Loss: 0.04373 | Avg Loss: 0.3473 | Prediction: 2.680872678756714 | Label: 1 | Time: 0.0101 | Avg Time: 0.03099 | Time Left: 42.83\n",
            "Epoch: 01/02 | Batch: 00506/01887 | Loss: 0.0698 | Avg Loss: 0.3468 | Prediction: -2.2363641262054443 | Label: 0 | Time: 0.004866 | Avg Time: 0.03094 | Time Left: 42.72\n",
            "Epoch: 01/02 | Batch: 00507/01887 | Loss: 0.05469 | Avg Loss: 0.3462 | Prediction: -2.2107269763946533 | Label: 0 | Time: 0.01578 | Avg Time: 0.03091 | Time Left: 42.65\n",
            "Epoch: 01/02 | Batch: 00508/01887 | Loss: 0.0442 | Avg Loss: 0.3456 | Prediction: -6.166688442230225 | Label: 0 | Time: 0.008969 | Avg Time: 0.03086 | Time Left: 42.56\n",
            "Epoch: 01/02 | Batch: 00509/01887 | Loss: 0.3802 | Avg Loss: 0.3457 | Prediction: -5.124514579772949 | Label: 0 | Time: 0.02306 | Avg Time: 0.03085 | Time Left: 42.51\n",
            "Epoch: 01/02 | Batch: 00510/01887 | Loss: 0.1572 | Avg Loss: 0.3453 | Prediction: 2.748851776123047 | Label: 1 | Time: 0.01324 | Avg Time: 0.03081 | Time Left: 42.43\n",
            "Epoch: 01/02 | Batch: 00511/01887 | Loss: 0.1178 | Avg Loss: 0.3448 | Prediction: -6.707354545593262 | Label: 0 | Time: 0.01154 | Avg Time: 0.03078 | Time Left: 42.35\n",
            "Epoch: 01/02 | Batch: 00512/01887 | Loss: 0.3661 | Avg Loss: 0.3449 | Prediction: 3.0663399696350098 | Label: 1 | Time: 0.006027 | Avg Time: 0.03073 | Time Left: 42.25\n",
            "Epoch: 01/02 | Batch: 00513/01887 | Loss: 0.03133 | Avg Loss: 0.3443 | Prediction: -5.773058891296387 | Label: 0 | Time: 0.01493 | Avg Time: 0.0307 | Time Left: 42.18\n",
            "Epoch: 01/02 | Batch: 00514/01887 | Loss: 0.03556 | Avg Loss: 0.3437 | Prediction: -5.470353603363037 | Label: 0 | Time: 0.01911 | Avg Time: 0.03068 | Time Left: 42.12\n",
            "Epoch: 01/02 | Batch: 00515/01887 | Loss: 0.1901 | Avg Loss: 0.3434 | Prediction: -5.226416110992432 | Label: 0 | Time: 0.01001 | Avg Time: 0.03064 | Time Left: 42.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-14 (_pin_memory_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
            "    do_one_step()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 508, in Client\n",
            "    answer_challenge(c, authkey)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 757, in answer_challenge\n",
            "    response = connection.recv_bytes(256)        # reject large message\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n"
          ]
        }
      ],
      "source": [
        "times = []\n",
        "losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(train_dataloader):\n",
        "\n",
        "        start = time()\n",
        "        outputs = model(data.to(device)).squeeze(1)\n",
        "        loss = criterion(outputs, targets.to(device).float())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        times.append(time() - start)\n",
        "\n",
        "        msg =  f'Epoch: {epoch+1:02}/{epochs:02} | '\n",
        "        msg += f'Batch: {batch_idx+1:05}/{len(train_dataloader):05} | '\n",
        "        msg += f'Loss: {losses[-1]:0.4} | '\n",
        "        msg += f'Avg Loss: {sum(losses)/len(losses):0.4} | '\n",
        "        msg += f'Prediction: {outputs[0]} | '\n",
        "        msg += f'Label: {targets[0]} | '\n",
        "        msg += f'Time: {times[-1]:0.4} | '\n",
        "        avg_time = sum(times)/len(times)\n",
        "        msg += f'Avg Time: {avg_time:0.4} | '\n",
        "        msg += f'Time Left: {avg_time * (len(train_dataloader) - (batch_idx + 1)):0.4}'\n",
        "        print(msg, flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-zpwrSaQ3Na"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for batch_idx, (data, targets) in enumerate(test_dataloader):\n",
        "\n",
        "        outputs = model(data.to(device))\n",
        "        predicted, _ = torch.max(outputs, 1)\n",
        "        for i in range(len(predicted)):\n",
        "          if predicted[i].item() < 0:\n",
        "            predictions.append(0)\n",
        "          else:\n",
        "            predictions.append(1)\n",
        "        labels.extend(targets.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiN5MNnOQMbL"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vczqKG8zQRQH"
      },
      "outputs": [],
      "source": [
        "print(accuracy_score(labels, predictions))\n",
        "print(confusion_matrix(labels, predictions))\n",
        "print(classification_report(labels, predictions))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}